{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1952187,"sourceType":"datasetVersion","datasetId":1165106},{"sourceId":10966846,"sourceType":"datasetVersion","datasetId":6823318}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git init\n!git remote add origin https://github.com/AlexOlsen/DeepWeeds\n!git pull origin master","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:15:18.815841Z","iopub.execute_input":"2025-03-09T05:15:18.816089Z","iopub.status.idle":"2025-03-09T05:15:19.779687Z","shell.execute_reply.started":"2025-03-09T05:15:18.816066Z","shell.execute_reply":"2025-03-09T05:15:19.778434Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n\u001b[33mhint: \u001b[m\n\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n\u001b[33mhint: \u001b[m\n\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n\u001b[33mhint: \u001b[m\n\u001b[33mhint: \tgit branch -m <name>\u001b[m\nInitialized empty Git repository in /kaggle/working/.git/\nremote: Enumerating objects: 37, done.\u001b[K\nremote: Counting objects: 100% (4/4), done.\u001b[K\nremote: Compressing objects: 100% (4/4), done.\u001b[K\nremote: Total 37 (delta 0), reused 2 (delta 0), pack-reused 33 (from 1)\u001b[K\nUnpacking objects: 100% (37/37), 556.80 KiB | 5.74 MiB/s, done.\nFrom https://github.com/AlexOlsen/DeepWeeds\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import datetime,time,os\nimport pandas as pd\nimport numpy as np\nimport csv\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\nfrom keras.optimizers import Adam\nfrom keras.models import Model, load_model\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import VGG19\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, GlobalAveragePooling2D\nimport keras\nfrom keras.applications.inception_v3 import InceptionV3\n\nimport gc\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:15:19.780991Z","iopub.execute_input":"2025-03-09T05:15:19.781362Z","iopub.status.idle":"2025-03-09T05:15:34.087921Z","shell.execute_reply.started":"2025-03-09T05:15:19.781314Z","shell.execute_reply":"2025-03-09T05:15:34.086926Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"OUTPUT_DIRECTORY=\"./output/\"\n# CONSTANTS \nLABEL_DIRECTORY = \"./labels/\"\nMODEL_DIRECTORY = \"./models/\"\nIMG_DIRECTORY = \"/kaggle/input/masked-images/Major_project\"\nRAW_IMG_SIZE = (224, 224)\nIMG_SIZE = (224, 224)\nINPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\nMAX_EPOCH = 100\nBATCH_SIZE = 32\nFOLDS = 5\nSTOPPING_PATIENCE = 4\nLR_PATIENCE = 16\nINITIAL_LR = 0.0001\nCLASSES = [0, 1, 2, 3, 4, 5, 6, 7, 8]\nCLASS_NAMES = ['Chinee Apple',\n               'Lantana',\n               'Parkinsonia',\n               'Parthenium',\n               'Prickly Acacia',\n               'Rubber Vine',\n               'Siam Weed',\n               'Snake Weed',\n               'Negatives']\n\n\n\noutput_directory = OUTPUT_DIRECTORY\nif not os.path.exists(output_directory):\n        os.makedirs(output_directory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:15:34.089115Z","iopub.execute_input":"2025-03-09T05:15:34.089753Z","iopub.status.idle":"2025-03-09T05:15:34.096113Z","shell.execute_reply.started":"2025-03-09T05:15:34.089701Z","shell.execute_reply":"2025-03-09T05:15:34.095187Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df=pd.read_csv(LABEL_DIRECTORY+\"labels.csv\")\nleast_freq=sorted(df.Species.value_counts())[0]\ntemp=pd.DataFrame()\nfor species in  set(df[\"Species\"]):\n    temp = pd.concat([temp,df[df[\"Species\"]==species].sample(least_freq,random_state=49)])\ntemp.to_csv(\"./resampled.csv\",index=False)\n\ndf=pd.read_csv(\"./resampled.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:15:34.097137Z","iopub.execute_input":"2025-03-09T05:15:34.097470Z","iopub.status.idle":"2025-03-09T05:15:34.223257Z","shell.execute_reply.started":"2025-03-09T05:15:34.097439Z","shell.execute_reply":"2025-03-09T05:15:34.222253Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df=pd.read_csv(\"./resampled.csv\")\none_hot=pd.get_dummies(df['Species'])\ndf=df.join(one_hot)\ndf=df.drop(columns=['Label','Species'],axis=1)\ndf.columns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:15:34.224189Z","iopub.execute_input":"2025-03-09T05:15:34.224529Z","iopub.status.idle":"2025-03-09T05:15:34.252728Z","shell.execute_reply.started":"2025-03-09T05:15:34.224494Z","shell.execute_reply":"2025-03-09T05:15:34.251748Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['Filename', 'Chinee apple', 'Lantana', 'Negative', 'Parkinsonia',\n       'Parthenium', 'Prickly acacia', 'Rubber vine', 'Siam weed',\n       'Snake weed'],\n      dtype='object')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_dataframe,test_dataframe=train_test_split(df,random_state=49,shuffle=True,train_size=0.75)\nval_dataframe,test_dataframe=train_test_split(test_dataframe,random_state=49,shuffle=True,test_size=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:15:34.254605Z","iopub.execute_input":"2025-03-09T05:15:34.254864Z","iopub.status.idle":"2025-03-09T05:15:34.262667Z","shell.execute_reply.started":"2025-03-09T05:15:34.254813Z","shell.execute_reply":"2025-03-09T05:15:34.261614Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# train_dataframe['Label']=to_categorical(train_dataframe['Label']).tolist()\n# val_dataframe['Label']  =to_categorical(val_dataframe['Label']).tolist()\n# test_dataframe['Label'] =to_categorical(test_dataframe['Label']).tolist()\n\ntrain_image_count = train_dataframe.shape[0]\nval_image_count = train_dataframe.shape[0]\ntest_image_count = test_dataframe.shape[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:16:06.894774Z","iopub.execute_input":"2025-03-09T05:16:06.895104Z","iopub.status.idle":"2025-03-09T05:16:06.899341Z","shell.execute_reply.started":"2025-03-09T05:16:06.895082Z","shell.execute_reply":"2025-03-09T05:16:06.898267Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"y_colums=['Chinee apple', 'Lantana', 'Negative', 'Parkinsonia','Parthenium', 'Prickly acacia', 'Rubber vine', 'Siam weed','Snake weed']\ntrain_data_generator = ImageDataGenerator(\n    rescale=1. / 255,\n    fill_mode=\"constant\",\n    shear_range=0.2,\n    zoom_range=(0.5, 1),\n    horizontal_flip=True,\n    rotation_range=360,\n    channel_shift_range=25,\n    brightness_range=(0.75, 1.25))\n# Validation image augmentation\nval_data_generator = ImageDataGenerator(\n    rescale=1. / 255,\n    fill_mode=\"constant\",\n    shear_range=0.2,\n    zoom_range=(0.5, 1),\n    horizontal_flip=True,\n    rotation_range=360,\n    channel_shift_range=25,\n    brightness_range=(0.75, 1.25))\n# No testing image augmentation (except for converting pixel values to floats)\ntest_data_generator = ImageDataGenerator(rescale=1. / 255)\ntrain_data_generator = train_data_generator.flow_from_dataframe(\n    train_dataframe,\n    IMG_DIRECTORY,\n    x_col='Filename',\n    y_col=y_colums,\n    target_size=RAW_IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    has_ext=True,\n    class_mode='raw')\n# Load validation images in batches from directory and apply rescaling\nval_data_generator = val_data_generator.flow_from_dataframe(\n    val_dataframe,\n    IMG_DIRECTORY,\n    x_col=\"Filename\",\n    y_col=y_colums,\n    target_size=RAW_IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    has_ext=True,\n    class_mode='raw')\n# Load test images in batches from directory and apply rescaling\ntest_data_generator = test_data_generator.flow_from_dataframe(\n    test_dataframe,\n    IMG_DIRECTORY,\n    x_col=\"Filename\",\n    y_col=y_colums,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    has_ext=True,\n    shuffle=False,\n    class_mode='raw')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:16:08.134644Z","iopub.execute_input":"2025-03-09T05:16:08.135029Z","iopub.status.idle":"2025-03-09T05:16:15.451119Z","shell.execute_reply.started":"2025-03-09T05:16:08.134998Z","shell.execute_reply":"2025-03-09T05:16:15.450053Z"}},"outputs":[{"name":"stdout","text":"Found 1959 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 4851 invalid image filename(s) in x_col=\"Filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 346 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 789 invalid image filename(s) in x_col=\"Filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 352 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 784 invalid image filename(s) in x_col=\"Filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\nbase_model = VGG19(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n\nx = base_model.output\n# Add a global average pooling layer\nx = GlobalAveragePooling2D(name='avg_pool')(x)\n# Add fully connected output layer with sigmoid activation for multi label classification\noutputs = Dense(len(CLASSES), activation='softmax', name='fc9')(x)\n# Assemble the modified model\nmodel = Model(inputs=base_model.input, outputs=outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:16:18.845422Z","iopub.execute_input":"2025-03-09T05:16:18.845783Z","iopub.status.idle":"2025-03-09T05:16:22.029393Z","shell.execute_reply.started":"2025-03-09T05:16:18.845754Z","shell.execute_reply":"2025-03-09T05:16:22.028623Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Checkpoints for training\nmodel_checkpoint = ModelCheckpoint(output_directory + \"lastbest-0.keras\", verbose=1, save_best_only=True,monitor='val_loss')\nearly_stopping = EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=STOPPING_PATIENCE,verbose=2,mode=\"auto\",restore_best_weights=True,start_from_epoch=10)\ntensorboard = TensorBoard(log_dir=output_directory, histogram_freq=0, write_graph=True, write_images=False)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.5, patience=LR_PATIENCE, min_lr=0.000003125)\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=INITIAL_LR),\n              loss=\"categorical_crossentropy\",\n              metrics=['categorical_accuracy'])\n\ncheckpoint_callback = ModelCheckpoint(filepath=output_directory+'model_checkpoint.keras',\n                                      monitor='val_loss',\n                                      verbose=1,\n                                      save_best_only=True,\n                                      mode='min')\n# csv_logger = CSVLogger(output_directory + \"training_metrics.csv\")\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n\nglobal_epoch = 0\nrestarts = 0\nlast_best_losses = []\nlast_best_epochs = []\n# Train model until MAX_EPOCH, restarting after each early stop when learning has plateaued\n\n# Define callbacks\n\nwhile global_epoch < MAX_EPOCH:\n    history = model.fit(\n        train_data_generator,\n        epochs=MAX_EPOCH - global_epoch,\n        validation_data=val_data_generator,\n        callbacks=[tensorboard, model_checkpoint, early_stopping, reduce_lr],\n        shuffle=False)\n    last_best_losses.append(min(history.history['val_loss']))\n    last_best_local_epoch = history.history['val_loss'].index(min(history.history['val_loss']))\n    last_best_epochs.append(global_epoch + last_best_local_epoch)\n\n    if early_stopping.stopped_epoch == 0:\n        print(\"Completed training after {} epochs.\".format(MAX_EPOCH))\n        break\n    else:\n        global_epoch = global_epoch + early_stopping.stopped_epoch - STOPPING_PATIENCE + 1\n        print(\"Early stopping triggered after local epoch {} (global epoch {}).\".format(\n            early_stopping.stopped_epoch, global_epoch))\n        print(\"Restarting from last best val_loss at local epoch {} (global epoch {}).\".format(\n            early_stopping.stopped_epoch - STOPPING_PATIENCE, global_epoch - STOPPING_PATIENCE))\n        restarts = restarts + 1\n        model.compile(loss= \"categorical_crossentropy\", optimizer=Adam(learning_rate=INITIAL_LR / 2 ** restarts),\n                      metrics=['categorical_accuracy'])\n        model_checkpoint = ModelCheckpoint(output_directory + \"lastbest-{}.keras\".format(restarts),\n                                           monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n        gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:16:24.903766Z","iopub.execute_input":"2025-03-09T05:16:24.904109Z","iopub.status.idle":"2025-03-09T08:47:30.887973Z","shell.execute_reply.started":"2025-03-09T05:16:24.904085Z","shell.execute_reply":"2025-03-09T08:47:30.886905Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - categorical_accuracy: 0.3007 - loss: 1.5612","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 1.29002, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - categorical_accuracy: 0.3016 - loss: 1.5585 - val_categorical_accuracy: 0.3988 - val_loss: 1.2900 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - categorical_accuracy: 0.4768 - loss: 1.1880\nEpoch 2: val_loss improved from 1.29002 to 1.04458, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 615ms/step - categorical_accuracy: 0.4774 - loss: 1.1874 - val_categorical_accuracy: 0.5000 - val_loss: 1.0446 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - categorical_accuracy: 0.5640 - loss: 1.0472\nEpoch 3: val_loss improved from 1.04458 to 0.93173, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 597ms/step - categorical_accuracy: 0.5646 - loss: 1.0465 - val_categorical_accuracy: 0.6358 - val_loss: 0.9317 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - categorical_accuracy: 0.6748 - loss: 0.8679\nEpoch 4: val_loss did not improve from 0.93173\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 589ms/step - categorical_accuracy: 0.6753 - loss: 0.8669 - val_categorical_accuracy: 0.6098 - val_loss: 1.0640 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - categorical_accuracy: 0.6568 - loss: 0.9379\nEpoch 5: val_loss improved from 0.93173 to 0.75383, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 606ms/step - categorical_accuracy: 0.6577 - loss: 0.9356 - val_categorical_accuracy: 0.7110 - val_loss: 0.7538 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - categorical_accuracy: 0.7718 - loss: 0.6509\nEpoch 6: val_loss improved from 0.75383 to 0.69793, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 618ms/step - categorical_accuracy: 0.7720 - loss: 0.6505 - val_categorical_accuracy: 0.7312 - val_loss: 0.6979 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - categorical_accuracy: 0.8159 - loss: 0.5638\nEpoch 7: val_loss improved from 0.69793 to 0.45921, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 627ms/step - categorical_accuracy: 0.8159 - loss: 0.5632 - val_categorical_accuracy: 0.8266 - val_loss: 0.4592 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - categorical_accuracy: 0.8369 - loss: 0.4935\nEpoch 8: val_loss did not improve from 0.45921\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 596ms/step - categorical_accuracy: 0.8371 - loss: 0.4929 - val_categorical_accuracy: 0.8324 - val_loss: 0.5414 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - categorical_accuracy: 0.8734 - loss: 0.3925\nEpoch 9: val_loss improved from 0.45921 to 0.38305, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 621ms/step - categorical_accuracy: 0.8732 - loss: 0.3932 - val_categorical_accuracy: 0.8671 - val_loss: 0.3830 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - categorical_accuracy: 0.8874 - loss: 0.3416\nEpoch 10: val_loss did not improve from 0.38305\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 612ms/step - categorical_accuracy: 0.8873 - loss: 0.3418 - val_categorical_accuracy: 0.8468 - val_loss: 0.4156 - learning_rate: 1.0000e-04\nEpoch 11/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - categorical_accuracy: 0.8834 - loss: 0.3540\nEpoch 11: val_loss did not improve from 0.38305\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 595ms/step - categorical_accuracy: 0.8831 - loss: 0.3548 - val_categorical_accuracy: 0.8439 - val_loss: 0.4356 - learning_rate: 1.0000e-04\nEpoch 12/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - categorical_accuracy: 0.8580 - loss: 0.4126\nEpoch 12: val_loss did not improve from 0.38305\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 578ms/step - categorical_accuracy: 0.8581 - loss: 0.4124 - val_categorical_accuracy: 0.8497 - val_loss: 0.3997 - learning_rate: 1.0000e-04\nEpoch 13/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - categorical_accuracy: 0.8968 - loss: 0.3056\nEpoch 13: val_loss did not improve from 0.38305\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 576ms/step - categorical_accuracy: 0.8968 - loss: 0.3056 - val_categorical_accuracy: 0.8237 - val_loss: 0.4015 - learning_rate: 1.0000e-04\nEpoch 14/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - categorical_accuracy: 0.8927 - loss: 0.3098\nEpoch 14: val_loss improved from 0.38305 to 0.37424, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 603ms/step - categorical_accuracy: 0.8926 - loss: 0.3102 - val_categorical_accuracy: 0.8815 - val_loss: 0.3742 - learning_rate: 1.0000e-04\nEpoch 15/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - categorical_accuracy: 0.8882 - loss: 0.2968\nEpoch 15: val_loss improved from 0.37424 to 0.35549, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 593ms/step - categorical_accuracy: 0.8883 - loss: 0.2966 - val_categorical_accuracy: 0.8873 - val_loss: 0.3555 - learning_rate: 1.0000e-04\nEpoch 16/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - categorical_accuracy: 0.9093 - loss: 0.2655\nEpoch 16: val_loss improved from 0.35549 to 0.32688, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 602ms/step - categorical_accuracy: 0.9093 - loss: 0.2655 - val_categorical_accuracy: 0.8960 - val_loss: 0.3269 - learning_rate: 1.0000e-04\nEpoch 17/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - categorical_accuracy: 0.9008 - loss: 0.2627\nEpoch 17: val_loss improved from 0.32688 to 0.28512, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 594ms/step - categorical_accuracy: 0.9008 - loss: 0.2629 - val_categorical_accuracy: 0.8873 - val_loss: 0.2851 - learning_rate: 1.0000e-04\nEpoch 18/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - categorical_accuracy: 0.9162 - loss: 0.2304\nEpoch 18: val_loss did not improve from 0.28512\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 587ms/step - categorical_accuracy: 0.9162 - loss: 0.2304 - val_categorical_accuracy: 0.9017 - val_loss: 0.2867 - learning_rate: 1.0000e-04\nEpoch 19/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - categorical_accuracy: 0.8923 - loss: 0.2847\nEpoch 19: val_loss improved from 0.28512 to 0.23371, saving model to ./output/lastbest-0.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 596ms/step - categorical_accuracy: 0.8925 - loss: 0.2843 - val_categorical_accuracy: 0.9075 - val_loss: 0.2337 - learning_rate: 1.0000e-04\nEpoch 20/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - categorical_accuracy: 0.9299 - loss: 0.2373\nEpoch 20: val_loss did not improve from 0.23371\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 562ms/step - categorical_accuracy: 0.9299 - loss: 0.2373 - val_categorical_accuracy: 0.8960 - val_loss: 0.2820 - learning_rate: 1.0000e-04\nEpoch 21/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - categorical_accuracy: 0.9216 - loss: 0.2182\nEpoch 21: val_loss did not improve from 0.23371\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 569ms/step - categorical_accuracy: 0.9215 - loss: 0.2183 - val_categorical_accuracy: 0.7341 - val_loss: 0.7067 - learning_rate: 1.0000e-04\nEpoch 22/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - categorical_accuracy: 0.9021 - loss: 0.2742\nEpoch 22: val_loss did not improve from 0.23371\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 562ms/step - categorical_accuracy: 0.9023 - loss: 0.2737 - val_categorical_accuracy: 0.8902 - val_loss: 0.3432 - learning_rate: 1.0000e-04\nEpoch 23/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - categorical_accuracy: 0.8996 - loss: 0.3102\nEpoch 23: val_loss did not improve from 0.23371\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 560ms/step - categorical_accuracy: 0.8999 - loss: 0.3092 - val_categorical_accuracy: 0.9104 - val_loss: 0.2341 - learning_rate: 1.0000e-04\nEpoch 24/100\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - categorical_accuracy: 0.9326 - loss: 0.1971\nEpoch 24: val_loss did not improve from 0.23371\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 580ms/step - categorical_accuracy: 0.9325 - loss: 0.1976 - val_categorical_accuracy: 0.8035 - val_loss: 0.6456 - learning_rate: 1.0000e-04\nEpoch 24: early stopping\nRestoring model weights from the end of the best epoch: 19.\nEarly stopping triggered after local epoch 23 (global epoch 20).\nRestarting from last best val_loss at local epoch 19 (global epoch 16).\nEpoch 1/80\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - categorical_accuracy: 0.9200 - loss: 0.2080\nEpoch 1: val_loss improved from inf to 0.22441, saving model to ./output/lastbest-1.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 662ms/step - categorical_accuracy: 0.9201 - loss: 0.2080 - val_categorical_accuracy: 0.9017 - val_loss: 0.2244 - learning_rate: 5.0000e-05\nEpoch 2/80\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - categorical_accuracy: 0.9456 - loss: 0.1637\nEpoch 2: val_loss improved from 0.22441 to 0.17294, saving model to ./output/lastbest-1.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 611ms/step - categorical_accuracy: 0.9456 - loss: 0.1637 - val_categorical_accuracy: 0.9393 - val_loss: 0.1729 - learning_rate: 5.0000e-05\nEpoch 3/80\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - categorical_accuracy: 0.9498 - loss: 0.1403\nEpoch 3: val_loss did not improve from 0.17294\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 601ms/step - categorical_accuracy: 0.9498 - loss: 0.1405 - val_categorical_accuracy: 0.9191 - val_loss: 0.2467 - learning_rate: 5.0000e-05\nEpoch 4/80\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - categorical_accuracy: 0.9527 - loss: 0.1420\nEpoch 4: val_loss did not improve from 0.17294\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 585ms/step - categorical_accuracy: 0.9527 - loss: 0.1420 - val_categorical_accuracy: 0.9133 - val_loss: 0.2335 - learning_rate: 5.0000e-05\nEpoch 5/80\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - categorical_accuracy: 0.9412 - loss: 0.1587\nEpoch 5: val_loss did not improve from 0.17294\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 590ms/step - categorical_accuracy: 0.9410 - loss: 0.1592 - val_categorical_accuracy: 0.8786 - val_loss: 0.3120 - learning_rate: 5.0000e-05\nEpoch 6/80\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - categorical_accuracy: 0.9364 - loss: 0.1815\nEpoch 6: val_loss did not improve from 0.17294\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 584ms/step - categorical_accuracy: 0.9366 - loss: 0.1812 - val_categorical_accuracy: 0.8728 - val_loss: 0.4196 - learning_rate: 5.0000e-05\nEpoch 7/80\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - categorical_accuracy: 0.9313 - loss: 0.1751\nEpoch 7: val_loss did not improve from 0.17294\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 601ms/step - categorical_accuracy: 0.9315 - loss: 0.1749 - val_categorical_accuracy: 0.9364 - val_loss: 0.1804 - learning_rate: 5.0000e-05\nEpoch 7: early stopping\nRestoring model weights from the end of the best epoch: 2.\nEarly stopping triggered after local epoch 6 (global epoch 23).\nRestarting from last best val_loss at local epoch 2 (global epoch 19).\nEpoch 1/77\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - categorical_accuracy: 0.9496 - loss: 0.1267\nEpoch 1: val_loss improved from inf to 0.19205, saving model to ./output/lastbest-2.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 659ms/step - categorical_accuracy: 0.9495 - loss: 0.1270 - val_categorical_accuracy: 0.9364 - val_loss: 0.1921 - learning_rate: 2.5000e-05\nEpoch 2/77\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - categorical_accuracy: 0.9604 - loss: 0.1275\nEpoch 2: val_loss did not improve from 0.19205\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 610ms/step - categorical_accuracy: 0.9604 - loss: 0.1273 - val_categorical_accuracy: 0.9162 - val_loss: 0.2671 - learning_rate: 2.5000e-05\nEpoch 3/77\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - categorical_accuracy: 0.9623 - loss: 0.1056\nEpoch 3: val_loss did not improve from 0.19205\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 598ms/step - categorical_accuracy: 0.9623 - loss: 0.1057 - val_categorical_accuracy: 0.9249 - val_loss: 0.2538 - learning_rate: 2.5000e-05\nEpoch 4/77\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - categorical_accuracy: 0.9712 - loss: 0.0981\nEpoch 4: val_loss improved from 0.19205 to 0.19185, saving model to ./output/lastbest-2.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 618ms/step - categorical_accuracy: 0.9712 - loss: 0.0981 - val_categorical_accuracy: 0.9364 - val_loss: 0.1918 - learning_rate: 2.5000e-05\nEpoch 5/77\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - categorical_accuracy: 0.9544 - loss: 0.1412\nEpoch 5: val_loss did not improve from 0.19185\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 594ms/step - categorical_accuracy: 0.9545 - loss: 0.1409 - val_categorical_accuracy: 0.8844 - val_loss: 0.3655 - learning_rate: 2.5000e-05\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 24).\nRestarting from last best val_loss at local epoch 0 (global epoch 20).\nEpoch 1/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - categorical_accuracy: 0.9662 - loss: 0.0959\nEpoch 1: val_loss improved from inf to 0.17671, saving model to ./output/lastbest-3.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 660ms/step - categorical_accuracy: 0.9661 - loss: 0.0961 - val_categorical_accuracy: 0.9277 - val_loss: 0.1767 - learning_rate: 1.2500e-05\nEpoch 2/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - categorical_accuracy: 0.9594 - loss: 0.1323\nEpoch 2: val_loss improved from 0.17671 to 0.13924, saving model to ./output/lastbest-3.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 612ms/step - categorical_accuracy: 0.9595 - loss: 0.1322 - val_categorical_accuracy: 0.9566 - val_loss: 0.1392 - learning_rate: 1.2500e-05\nEpoch 3/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - categorical_accuracy: 0.9754 - loss: 0.0847\nEpoch 3: val_loss did not improve from 0.13924\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 603ms/step - categorical_accuracy: 0.9752 - loss: 0.0849 - val_categorical_accuracy: 0.9393 - val_loss: 0.1727 - learning_rate: 1.2500e-05\nEpoch 4/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - categorical_accuracy: 0.9649 - loss: 0.0979\nEpoch 4: val_loss improved from 0.13924 to 0.13750, saving model to ./output/lastbest-3.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 617ms/step - categorical_accuracy: 0.9649 - loss: 0.0979 - val_categorical_accuracy: 0.9480 - val_loss: 0.1375 - learning_rate: 1.2500e-05\nEpoch 5/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - categorical_accuracy: 0.9705 - loss: 0.0992\nEpoch 5: val_loss did not improve from 0.13750\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 599ms/step - categorical_accuracy: 0.9705 - loss: 0.0990 - val_categorical_accuracy: 0.9480 - val_loss: 0.1446 - learning_rate: 1.2500e-05\nEpoch 6/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - categorical_accuracy: 0.9690 - loss: 0.0974\nEpoch 6: val_loss did not improve from 0.13750\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 596ms/step - categorical_accuracy: 0.9691 - loss: 0.0972 - val_categorical_accuracy: 0.9393 - val_loss: 0.1931 - learning_rate: 1.2500e-05\nEpoch 7/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - categorical_accuracy: 0.9754 - loss: 0.0840\nEpoch 7: val_loss did not improve from 0.13750\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 584ms/step - categorical_accuracy: 0.9754 - loss: 0.0841 - val_categorical_accuracy: 0.9306 - val_loss: 0.2234 - learning_rate: 1.2500e-05\nEpoch 8/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - categorical_accuracy: 0.9777 - loss: 0.0674\nEpoch 8: val_loss did not improve from 0.13750\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 592ms/step - categorical_accuracy: 0.9776 - loss: 0.0676 - val_categorical_accuracy: 0.9364 - val_loss: 0.2414 - learning_rate: 1.2500e-05\nEpoch 9/76\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - categorical_accuracy: 0.9679 - loss: 0.0827\nEpoch 9: val_loss did not improve from 0.13750\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 592ms/step - categorical_accuracy: 0.9680 - loss: 0.0827 - val_categorical_accuracy: 0.9480 - val_loss: 0.1814 - learning_rate: 1.2500e-05\nEpoch 9: early stopping\nRestoring model weights from the end of the best epoch: 4.\nEarly stopping triggered after local epoch 8 (global epoch 29).\nRestarting from last best val_loss at local epoch 4 (global epoch 25).\nEpoch 1/71\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - categorical_accuracy: 0.9703 - loss: 0.0880\nEpoch 1: val_loss improved from inf to 0.18249, saving model to ./output/lastbest-4.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 660ms/step - categorical_accuracy: 0.9703 - loss: 0.0879 - val_categorical_accuracy: 0.9422 - val_loss: 0.1825 - learning_rate: 6.2500e-06\nEpoch 2/71\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - categorical_accuracy: 0.9755 - loss: 0.0829\nEpoch 2: val_loss did not improve from 0.18249\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 592ms/step - categorical_accuracy: 0.9755 - loss: 0.0829 - val_categorical_accuracy: 0.9335 - val_loss: 0.1885 - learning_rate: 6.2500e-06\nEpoch 3/71\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - categorical_accuracy: 0.9832 - loss: 0.0610\nEpoch 3: val_loss improved from 0.18249 to 0.16711, saving model to ./output/lastbest-4.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 620ms/step - categorical_accuracy: 0.9831 - loss: 0.0613 - val_categorical_accuracy: 0.9538 - val_loss: 0.1671 - learning_rate: 6.2500e-06\nEpoch 4/71\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - categorical_accuracy: 0.9722 - loss: 0.0748\nEpoch 4: val_loss improved from 0.16711 to 0.14080, saving model to ./output/lastbest-4.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 639ms/step - categorical_accuracy: 0.9723 - loss: 0.0748 - val_categorical_accuracy: 0.9422 - val_loss: 0.1408 - learning_rate: 6.2500e-06\nEpoch 5/71\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - categorical_accuracy: 0.9770 - loss: 0.0802\nEpoch 5: val_loss did not improve from 0.14080\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 616ms/step - categorical_accuracy: 0.9770 - loss: 0.0801 - val_categorical_accuracy: 0.9480 - val_loss: 0.2025 - learning_rate: 6.2500e-06\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 30).\nRestarting from last best val_loss at local epoch 0 (global epoch 26).\nEpoch 1/70\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - categorical_accuracy: 0.9743 - loss: 0.0732\nEpoch 1: val_loss improved from inf to 0.16810, saving model to ./output/lastbest-5.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 676ms/step - categorical_accuracy: 0.9743 - loss: 0.0733 - val_categorical_accuracy: 0.9422 - val_loss: 0.1681 - learning_rate: 3.1250e-06\nEpoch 2/70\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - categorical_accuracy: 0.9711 - loss: 0.0837\nEpoch 2: val_loss did not improve from 0.16810\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 596ms/step - categorical_accuracy: 0.9712 - loss: 0.0835 - val_categorical_accuracy: 0.9422 - val_loss: 0.1720 - learning_rate: 3.1250e-06\nEpoch 3/70\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - categorical_accuracy: 0.9796 - loss: 0.0642\nEpoch 3: val_loss improved from 0.16810 to 0.14821, saving model to ./output/lastbest-5.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 618ms/step - categorical_accuracy: 0.9795 - loss: 0.0644 - val_categorical_accuracy: 0.9509 - val_loss: 0.1482 - learning_rate: 3.1250e-06\nEpoch 4/70\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - categorical_accuracy: 0.9760 - loss: 0.0729\nEpoch 4: val_loss did not improve from 0.14821\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 600ms/step - categorical_accuracy: 0.9760 - loss: 0.0728 - val_categorical_accuracy: 0.9595 - val_loss: 0.1626 - learning_rate: 3.1250e-06\nEpoch 5/70\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - categorical_accuracy: 0.9733 - loss: 0.0838\nEpoch 5: val_loss did not improve from 0.14821\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 589ms/step - categorical_accuracy: 0.9734 - loss: 0.0836 - val_categorical_accuracy: 0.9422 - val_loss: 0.1618 - learning_rate: 3.1250e-06\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 31).\nRestarting from last best val_loss at local epoch 0 (global epoch 27).\nEpoch 1/69\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - categorical_accuracy: 0.9783 - loss: 0.0731\nEpoch 1: val_loss improved from inf to 0.16752, saving model to ./output/lastbest-6.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 667ms/step - categorical_accuracy: 0.9783 - loss: 0.0731 - val_categorical_accuracy: 0.9451 - val_loss: 0.1675 - learning_rate: 1.5625e-06\nEpoch 2/69\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - categorical_accuracy: 0.9742 - loss: 0.0833\nEpoch 2: val_loss improved from 0.16752 to 0.16566, saving model to ./output/lastbest-6.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 615ms/step - categorical_accuracy: 0.9742 - loss: 0.0832 - val_categorical_accuracy: 0.9393 - val_loss: 0.1657 - learning_rate: 1.5625e-06\nEpoch 3/69\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - categorical_accuracy: 0.9829 - loss: 0.0620\nEpoch 3: val_loss did not improve from 0.16566\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 589ms/step - categorical_accuracy: 0.9829 - loss: 0.0621 - val_categorical_accuracy: 0.9393 - val_loss: 0.1987 - learning_rate: 1.5625e-06\nEpoch 4/69\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - categorical_accuracy: 0.9805 - loss: 0.0766\nEpoch 4: val_loss improved from 0.16566 to 0.15665, saving model to ./output/lastbest-6.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 615ms/step - categorical_accuracy: 0.9805 - loss: 0.0765 - val_categorical_accuracy: 0.9480 - val_loss: 0.1567 - learning_rate: 1.5625e-06\nEpoch 5/69\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - categorical_accuracy: 0.9729 - loss: 0.0931\nEpoch 5: val_loss did not improve from 0.15665\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 573ms/step - categorical_accuracy: 0.9729 - loss: 0.0928 - val_categorical_accuracy: 0.9538 - val_loss: 0.1652 - learning_rate: 1.5625e-06\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 32).\nRestarting from last best val_loss at local epoch 0 (global epoch 28).\nEpoch 1/68\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - categorical_accuracy: 0.9784 - loss: 0.0702\nEpoch 1: val_loss improved from inf to 0.15383, saving model to ./output/lastbest-7.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 615ms/step - categorical_accuracy: 0.9783 - loss: 0.0703 - val_categorical_accuracy: 0.9422 - val_loss: 0.1538 - learning_rate: 7.8125e-07\nEpoch 2/68\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - categorical_accuracy: 0.9765 - loss: 0.0903\nEpoch 2: val_loss did not improve from 0.15383\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 549ms/step - categorical_accuracy: 0.9765 - loss: 0.0900 - val_categorical_accuracy: 0.9364 - val_loss: 0.1678 - learning_rate: 7.8125e-07\nEpoch 3/68\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - categorical_accuracy: 0.9798 - loss: 0.0649\nEpoch 3: val_loss did not improve from 0.15383\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 541ms/step - categorical_accuracy: 0.9797 - loss: 0.0652 - val_categorical_accuracy: 0.9480 - val_loss: 0.1728 - learning_rate: 7.8125e-07\nEpoch 4/68\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - categorical_accuracy: 0.9742 - loss: 0.0840\nEpoch 4: val_loss did not improve from 0.15383\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 544ms/step - categorical_accuracy: 0.9742 - loss: 0.0838 - val_categorical_accuracy: 0.9509 - val_loss: 0.1633 - learning_rate: 7.8125e-07\nEpoch 5/68\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - categorical_accuracy: 0.9756 - loss: 0.0816\nEpoch 5: val_loss did not improve from 0.15383\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - categorical_accuracy: 0.9757 - loss: 0.0815 - val_categorical_accuracy: 0.9566 - val_loss: 0.1623 - learning_rate: 7.8125e-07\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 33).\nRestarting from last best val_loss at local epoch 0 (global epoch 29).\nEpoch 1/67\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - categorical_accuracy: 0.9797 - loss: 0.0608\nEpoch 1: val_loss improved from inf to 0.20616, saving model to ./output/lastbest-8.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 604ms/step - categorical_accuracy: 0.9796 - loss: 0.0610 - val_categorical_accuracy: 0.9509 - val_loss: 0.2062 - learning_rate: 3.9062e-07\nEpoch 2/67\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9807 - loss: 0.0655\nEpoch 2: val_loss improved from 0.20616 to 0.17417, saving model to ./output/lastbest-8.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 550ms/step - categorical_accuracy: 0.9806 - loss: 0.0656 - val_categorical_accuracy: 0.9364 - val_loss: 0.1742 - learning_rate: 3.9062e-07\nEpoch 3/67\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9807 - loss: 0.0735\nEpoch 3: val_loss improved from 0.17417 to 0.14072, saving model to ./output/lastbest-8.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - categorical_accuracy: 0.9808 - loss: 0.0733 - val_categorical_accuracy: 0.9538 - val_loss: 0.1407 - learning_rate: 3.9062e-07\nEpoch 4/67\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - categorical_accuracy: 0.9706 - loss: 0.0705\nEpoch 4: val_loss did not improve from 0.14072\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 541ms/step - categorical_accuracy: 0.9706 - loss: 0.0705 - val_categorical_accuracy: 0.9393 - val_loss: 0.2023 - learning_rate: 3.9062e-07\nEpoch 5/67\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9734 - loss: 0.0783\nEpoch 5: val_loss did not improve from 0.14072\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 533ms/step - categorical_accuracy: 0.9735 - loss: 0.0782 - val_categorical_accuracy: 0.9509 - val_loss: 0.1733 - learning_rate: 3.9062e-07\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 34).\nRestarting from last best val_loss at local epoch 0 (global epoch 30).\nEpoch 1/66\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - categorical_accuracy: 0.9816 - loss: 0.0812\nEpoch 1: val_loss improved from inf to 0.16233, saving model to ./output/lastbest-9.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 608ms/step - categorical_accuracy: 0.9816 - loss: 0.0810 - val_categorical_accuracy: 0.9538 - val_loss: 0.1623 - learning_rate: 1.9531e-07\nEpoch 2/66\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9803 - loss: 0.0718\nEpoch 2: val_loss improved from 0.16233 to 0.15827, saving model to ./output/lastbest-9.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 554ms/step - categorical_accuracy: 0.9803 - loss: 0.0717 - val_categorical_accuracy: 0.9480 - val_loss: 0.1583 - learning_rate: 1.9531e-07\nEpoch 3/66\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9854 - loss: 0.0541\nEpoch 3: val_loss did not improve from 0.15827\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 537ms/step - categorical_accuracy: 0.9854 - loss: 0.0542 - val_categorical_accuracy: 0.9393 - val_loss: 0.1915 - learning_rate: 1.9531e-07\nEpoch 4/66\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - categorical_accuracy: 0.9815 - loss: 0.0672\nEpoch 4: val_loss did not improve from 0.15827\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9814 - loss: 0.0672 - val_categorical_accuracy: 0.9509 - val_loss: 0.1756 - learning_rate: 1.9531e-07\nEpoch 5/66\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9748 - loss: 0.0673\nEpoch 5: val_loss improved from 0.15827 to 0.15131, saving model to ./output/lastbest-9.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9748 - loss: 0.0673 - val_categorical_accuracy: 0.9480 - val_loss: 0.1513 - learning_rate: 1.9531e-07\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 35).\nRestarting from last best val_loss at local epoch 0 (global epoch 31).\nEpoch 1/65\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - categorical_accuracy: 0.9828 - loss: 0.0576\nEpoch 1: val_loss improved from inf to 0.16718, saving model to ./output/lastbest-10.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 598ms/step - categorical_accuracy: 0.9827 - loss: 0.0577 - val_categorical_accuracy: 0.9509 - val_loss: 0.1672 - learning_rate: 9.7656e-08\nEpoch 2/65\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - categorical_accuracy: 0.9769 - loss: 0.0667\nEpoch 2: val_loss did not improve from 0.16718\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 550ms/step - categorical_accuracy: 0.9769 - loss: 0.0667 - val_categorical_accuracy: 0.9566 - val_loss: 0.1776 - learning_rate: 9.7656e-08\nEpoch 3/65\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - categorical_accuracy: 0.9804 - loss: 0.0621\nEpoch 3: val_loss did not improve from 0.16718\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 544ms/step - categorical_accuracy: 0.9804 - loss: 0.0622 - val_categorical_accuracy: 0.9422 - val_loss: 0.1763 - learning_rate: 9.7656e-08\nEpoch 4/65\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - categorical_accuracy: 0.9872 - loss: 0.0515\nEpoch 4: val_loss improved from 0.16718 to 0.14487, saving model to ./output/lastbest-10.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 561ms/step - categorical_accuracy: 0.9871 - loss: 0.0517 - val_categorical_accuracy: 0.9624 - val_loss: 0.1449 - learning_rate: 9.7656e-08\nEpoch 5/65\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - categorical_accuracy: 0.9836 - loss: 0.0581\nEpoch 5: val_loss did not improve from 0.14487\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 542ms/step - categorical_accuracy: 0.9835 - loss: 0.0583 - val_categorical_accuracy: 0.9480 - val_loss: 0.1782 - learning_rate: 9.7656e-08\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 36).\nRestarting from last best val_loss at local epoch 0 (global epoch 32).\nEpoch 1/64\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - categorical_accuracy: 0.9830 - loss: 0.0584\nEpoch 1: val_loss improved from inf to 0.20188, saving model to ./output/lastbest-11.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 602ms/step - categorical_accuracy: 0.9830 - loss: 0.0585 - val_categorical_accuracy: 0.9451 - val_loss: 0.2019 - learning_rate: 4.8828e-08\nEpoch 2/64\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - categorical_accuracy: 0.9734 - loss: 0.0857\nEpoch 2: val_loss improved from 0.20188 to 0.16163, saving model to ./output/lastbest-11.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 558ms/step - categorical_accuracy: 0.9735 - loss: 0.0855 - val_categorical_accuracy: 0.9480 - val_loss: 0.1616 - learning_rate: 4.8828e-08\nEpoch 3/64\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9764 - loss: 0.0741\nEpoch 3: val_loss did not improve from 0.16163\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 538ms/step - categorical_accuracy: 0.9764 - loss: 0.0740 - val_categorical_accuracy: 0.9451 - val_loss: 0.1865 - learning_rate: 4.8828e-08\nEpoch 4/64\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9794 - loss: 0.0670\nEpoch 4: val_loss did not improve from 0.16163\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 536ms/step - categorical_accuracy: 0.9794 - loss: 0.0670 - val_categorical_accuracy: 0.9422 - val_loss: 0.1625 - learning_rate: 4.8828e-08\nEpoch 5/64\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9735 - loss: 0.0716\nEpoch 5: val_loss improved from 0.16163 to 0.14020, saving model to ./output/lastbest-11.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 551ms/step - categorical_accuracy: 0.9736 - loss: 0.0716 - val_categorical_accuracy: 0.9509 - val_loss: 0.1402 - learning_rate: 4.8828e-08\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 37).\nRestarting from last best val_loss at local epoch 0 (global epoch 33).\nEpoch 1/63\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - categorical_accuracy: 0.9771 - loss: 0.0673\nEpoch 1: val_loss improved from inf to 0.15870, saving model to ./output/lastbest-12.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 598ms/step - categorical_accuracy: 0.9771 - loss: 0.0673 - val_categorical_accuracy: 0.9393 - val_loss: 0.1587 - learning_rate: 2.4414e-08\nEpoch 2/63\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - categorical_accuracy: 0.9741 - loss: 0.0806\nEpoch 2: val_loss did not improve from 0.15870\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - categorical_accuracy: 0.9742 - loss: 0.0804 - val_categorical_accuracy: 0.9451 - val_loss: 0.1602 - learning_rate: 2.4414e-08\nEpoch 3/63\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - categorical_accuracy: 0.9768 - loss: 0.0836\nEpoch 3: val_loss did not improve from 0.15870\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9769 - loss: 0.0835 - val_categorical_accuracy: 0.9480 - val_loss: 0.1744 - learning_rate: 2.4414e-08\nEpoch 4/63\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9850 - loss: 0.0543\nEpoch 4: val_loss improved from 0.15870 to 0.14818, saving model to ./output/lastbest-12.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 553ms/step - categorical_accuracy: 0.9849 - loss: 0.0545 - val_categorical_accuracy: 0.9393 - val_loss: 0.1482 - learning_rate: 2.4414e-08\nEpoch 5/63\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9713 - loss: 0.0718\nEpoch 5: val_loss did not improve from 0.14818\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 526ms/step - categorical_accuracy: 0.9713 - loss: 0.0718 - val_categorical_accuracy: 0.9422 - val_loss: 0.1659 - learning_rate: 2.4414e-08\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 38).\nRestarting from last best val_loss at local epoch 0 (global epoch 34).\nEpoch 1/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - categorical_accuracy: 0.9821 - loss: 0.0681\nEpoch 1: val_loss improved from inf to 0.14320, saving model to ./output/lastbest-13.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 596ms/step - categorical_accuracy: 0.9821 - loss: 0.0681 - val_categorical_accuracy: 0.9509 - val_loss: 0.1432 - learning_rate: 1.2207e-08\nEpoch 2/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9841 - loss: 0.0592\nEpoch 2: val_loss did not improve from 0.14320\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9841 - loss: 0.0594 - val_categorical_accuracy: 0.9509 - val_loss: 0.1583 - learning_rate: 1.2207e-08\nEpoch 3/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9769 - loss: 0.0771\nEpoch 3: val_loss improved from 0.14320 to 0.13446, saving model to ./output/lastbest-13.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 549ms/step - categorical_accuracy: 0.9769 - loss: 0.0771 - val_categorical_accuracy: 0.9509 - val_loss: 0.1345 - learning_rate: 1.2207e-08\nEpoch 4/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9828 - loss: 0.0694\nEpoch 4: val_loss did not improve from 0.13446\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9828 - loss: 0.0693 - val_categorical_accuracy: 0.9566 - val_loss: 0.1398 - learning_rate: 1.2207e-08\nEpoch 5/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9813 - loss: 0.0623\nEpoch 5: val_loss did not improve from 0.13446\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9813 - loss: 0.0625 - val_categorical_accuracy: 0.9422 - val_loss: 0.1599 - learning_rate: 1.2207e-08\nEpoch 6/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9821 - loss: 0.0626\nEpoch 6: val_loss did not improve from 0.13446\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9820 - loss: 0.0627 - val_categorical_accuracy: 0.9451 - val_loss: 0.1413 - learning_rate: 1.2207e-08\nEpoch 7/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - categorical_accuracy: 0.9839 - loss: 0.0646\nEpoch 7: val_loss did not improve from 0.13446\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 520ms/step - categorical_accuracy: 0.9839 - loss: 0.0647 - val_categorical_accuracy: 0.9422 - val_loss: 0.1749 - learning_rate: 1.2207e-08\nEpoch 8/62\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9814 - loss: 0.0680\nEpoch 8: val_loss did not improve from 0.13446\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9813 - loss: 0.0681 - val_categorical_accuracy: 0.9422 - val_loss: 0.1751 - learning_rate: 1.2207e-08\nEpoch 8: early stopping\nRestoring model weights from the end of the best epoch: 3.\nEarly stopping triggered after local epoch 7 (global epoch 42).\nRestarting from last best val_loss at local epoch 3 (global epoch 38).\nEpoch 1/58\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - categorical_accuracy: 0.9765 - loss: 0.0766\nEpoch 1: val_loss improved from inf to 0.15054, saving model to ./output/lastbest-14.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 602ms/step - categorical_accuracy: 0.9765 - loss: 0.0766 - val_categorical_accuracy: 0.9538 - val_loss: 0.1505 - learning_rate: 6.1035e-09\nEpoch 2/58\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9816 - loss: 0.0613\nEpoch 2: val_loss did not improve from 0.15054\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - categorical_accuracy: 0.9816 - loss: 0.0613 - val_categorical_accuracy: 0.9480 - val_loss: 0.1935 - learning_rate: 6.1035e-09\nEpoch 3/58\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - categorical_accuracy: 0.9733 - loss: 0.0803\nEpoch 3: val_loss did not improve from 0.15054\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 539ms/step - categorical_accuracy: 0.9733 - loss: 0.0802 - val_categorical_accuracy: 0.9480 - val_loss: 0.1561 - learning_rate: 6.1035e-09\nEpoch 4/58\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - categorical_accuracy: 0.9789 - loss: 0.0685\nEpoch 4: val_loss did not improve from 0.15054\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 547ms/step - categorical_accuracy: 0.9790 - loss: 0.0686 - val_categorical_accuracy: 0.9509 - val_loss: 0.1677 - learning_rate: 6.1035e-09\nEpoch 5/58\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - categorical_accuracy: 0.9806 - loss: 0.0694\nEpoch 5: val_loss did not improve from 0.15054\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 544ms/step - categorical_accuracy: 0.9806 - loss: 0.0694 - val_categorical_accuracy: 0.9509 - val_loss: 0.1625 - learning_rate: 6.1035e-09\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 43).\nRestarting from last best val_loss at local epoch 0 (global epoch 39).\nEpoch 1/57\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - categorical_accuracy: 0.9809 - loss: 0.0565\nEpoch 1: val_loss improved from inf to 0.15436, saving model to ./output/lastbest-15.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 609ms/step - categorical_accuracy: 0.9809 - loss: 0.0567 - val_categorical_accuracy: 0.9509 - val_loss: 0.1544 - learning_rate: 3.0518e-09\nEpoch 2/57\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - categorical_accuracy: 0.9769 - loss: 0.0608\nEpoch 2: val_loss did not improve from 0.15436\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 526ms/step - categorical_accuracy: 0.9769 - loss: 0.0609 - val_categorical_accuracy: 0.9480 - val_loss: 0.1770 - learning_rate: 3.0518e-09\nEpoch 3/57\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - categorical_accuracy: 0.9852 - loss: 0.0556\nEpoch 3: val_loss improved from 0.15436 to 0.14759, saving model to ./output/lastbest-15.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 560ms/step - categorical_accuracy: 0.9851 - loss: 0.0558 - val_categorical_accuracy: 0.9538 - val_loss: 0.1476 - learning_rate: 3.0518e-09\nEpoch 4/57\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - categorical_accuracy: 0.9784 - loss: 0.0662\nEpoch 4: val_loss did not improve from 0.14759\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9784 - loss: 0.0663 - val_categorical_accuracy: 0.9364 - val_loss: 0.1856 - learning_rate: 3.0518e-09\nEpoch 5/57\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - categorical_accuracy: 0.9780 - loss: 0.0681\nEpoch 5: val_loss improved from 0.14759 to 0.14646, saving model to ./output/lastbest-15.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 560ms/step - categorical_accuracy: 0.9780 - loss: 0.0680 - val_categorical_accuracy: 0.9509 - val_loss: 0.1465 - learning_rate: 3.0518e-09\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 44).\nRestarting from last best val_loss at local epoch 0 (global epoch 40).\nEpoch 1/56\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - categorical_accuracy: 0.9793 - loss: 0.0692\nEpoch 1: val_loss improved from inf to 0.18487, saving model to ./output/lastbest-16.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 602ms/step - categorical_accuracy: 0.9793 - loss: 0.0692 - val_categorical_accuracy: 0.9451 - val_loss: 0.1849 - learning_rate: 1.5259e-09\nEpoch 2/56\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9740 - loss: 0.0687\nEpoch 2: val_loss improved from 0.18487 to 0.14472, saving model to ./output/lastbest-16.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 554ms/step - categorical_accuracy: 0.9740 - loss: 0.0687 - val_categorical_accuracy: 0.9480 - val_loss: 0.1447 - learning_rate: 1.5259e-09\nEpoch 3/56\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9793 - loss: 0.0670\nEpoch 3: val_loss did not improve from 0.14472\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9793 - loss: 0.0670 - val_categorical_accuracy: 0.9480 - val_loss: 0.1598 - learning_rate: 1.5259e-09\nEpoch 4/56\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9784 - loss: 0.0604\nEpoch 4: val_loss did not improve from 0.14472\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - categorical_accuracy: 0.9784 - loss: 0.0605 - val_categorical_accuracy: 0.9595 - val_loss: 0.1579 - learning_rate: 1.5259e-09\nEpoch 5/56\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9759 - loss: 0.0783\nEpoch 5: val_loss did not improve from 0.14472\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 533ms/step - categorical_accuracy: 0.9759 - loss: 0.0783 - val_categorical_accuracy: 0.9480 - val_loss: 0.1826 - learning_rate: 1.5259e-09\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 45).\nRestarting from last best val_loss at local epoch 0 (global epoch 41).\nEpoch 1/55\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - categorical_accuracy: 0.9809 - loss: 0.0628\nEpoch 1: val_loss improved from inf to 0.17493, saving model to ./output/lastbest-17.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 607ms/step - categorical_accuracy: 0.9809 - loss: 0.0628 - val_categorical_accuracy: 0.9480 - val_loss: 0.1749 - learning_rate: 7.6294e-10\nEpoch 2/55\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - categorical_accuracy: 0.9773 - loss: 0.0671\nEpoch 2: val_loss did not improve from 0.17493\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - categorical_accuracy: 0.9773 - loss: 0.0672 - val_categorical_accuracy: 0.9393 - val_loss: 0.1901 - learning_rate: 7.6294e-10\nEpoch 3/55\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - categorical_accuracy: 0.9763 - loss: 0.0648\nEpoch 3: val_loss improved from 0.17493 to 0.16568, saving model to ./output/lastbest-17.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 556ms/step - categorical_accuracy: 0.9763 - loss: 0.0649 - val_categorical_accuracy: 0.9624 - val_loss: 0.1657 - learning_rate: 7.6294e-10\nEpoch 4/55\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - categorical_accuracy: 0.9740 - loss: 0.0753\nEpoch 4: val_loss improved from 0.16568 to 0.13742, saving model to ./output/lastbest-17.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 560ms/step - categorical_accuracy: 0.9741 - loss: 0.0752 - val_categorical_accuracy: 0.9595 - val_loss: 0.1374 - learning_rate: 7.6294e-10\nEpoch 5/55\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - categorical_accuracy: 0.9776 - loss: 0.0681\nEpoch 5: val_loss did not improve from 0.13742\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9776 - loss: 0.0682 - val_categorical_accuracy: 0.9566 - val_loss: 0.1606 - learning_rate: 7.6294e-10\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 46).\nRestarting from last best val_loss at local epoch 0 (global epoch 42).\nEpoch 1/54\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - categorical_accuracy: 0.9851 - loss: 0.0557\nEpoch 1: val_loss improved from inf to 0.15502, saving model to ./output/lastbest-18.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 605ms/step - categorical_accuracy: 0.9851 - loss: 0.0558 - val_categorical_accuracy: 0.9451 - val_loss: 0.1550 - learning_rate: 3.8147e-10\nEpoch 2/54\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - categorical_accuracy: 0.9759 - loss: 0.0743\nEpoch 2: val_loss did not improve from 0.15502\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 538ms/step - categorical_accuracy: 0.9759 - loss: 0.0742 - val_categorical_accuracy: 0.9509 - val_loss: 0.1666 - learning_rate: 3.8147e-10\nEpoch 3/54\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - categorical_accuracy: 0.9832 - loss: 0.0616\nEpoch 3: val_loss did not improve from 0.15502\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9831 - loss: 0.0616 - val_categorical_accuracy: 0.9422 - val_loss: 0.1795 - learning_rate: 3.8147e-10\nEpoch 4/54\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - categorical_accuracy: 0.9745 - loss: 0.0812\nEpoch 4: val_loss did not improve from 0.15502\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 542ms/step - categorical_accuracy: 0.9746 - loss: 0.0811 - val_categorical_accuracy: 0.9393 - val_loss: 0.2153 - learning_rate: 3.8147e-10\nEpoch 5/54\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - categorical_accuracy: 0.9753 - loss: 0.0668\nEpoch 5: val_loss did not improve from 0.15502\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 537ms/step - categorical_accuracy: 0.9753 - loss: 0.0669 - val_categorical_accuracy: 0.9480 - val_loss: 0.1610 - learning_rate: 3.8147e-10\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 47).\nRestarting from last best val_loss at local epoch 0 (global epoch 43).\nEpoch 1/53\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - categorical_accuracy: 0.9793 - loss: 0.0618\nEpoch 1: val_loss improved from inf to 0.15927, saving model to ./output/lastbest-19.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 596ms/step - categorical_accuracy: 0.9793 - loss: 0.0619 - val_categorical_accuracy: 0.9566 - val_loss: 0.1593 - learning_rate: 1.9073e-10\nEpoch 2/53\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - categorical_accuracy: 0.9739 - loss: 0.0814\nEpoch 2: val_loss did not improve from 0.15927\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 521ms/step - categorical_accuracy: 0.9740 - loss: 0.0813 - val_categorical_accuracy: 0.9480 - val_loss: 0.1873 - learning_rate: 1.9073e-10\nEpoch 3/53\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9795 - loss: 0.0717\nEpoch 3: val_loss improved from 0.15927 to 0.15705, saving model to ./output/lastbest-19.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - categorical_accuracy: 0.9795 - loss: 0.0716 - val_categorical_accuracy: 0.9566 - val_loss: 0.1571 - learning_rate: 1.9073e-10\nEpoch 4/53\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9729 - loss: 0.0730\nEpoch 4: val_loss did not improve from 0.15705\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9729 - loss: 0.0730 - val_categorical_accuracy: 0.9422 - val_loss: 0.1784 - learning_rate: 1.9073e-10\nEpoch 5/53\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9820 - loss: 0.0720\nEpoch 5: val_loss did not improve from 0.15705\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9820 - loss: 0.0719 - val_categorical_accuracy: 0.9306 - val_loss: 0.1950 - learning_rate: 1.9073e-10\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 48).\nRestarting from last best val_loss at local epoch 0 (global epoch 44).\nEpoch 1/52\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - categorical_accuracy: 0.9762 - loss: 0.0641\nEpoch 1: val_loss improved from inf to 0.13880, saving model to ./output/lastbest-20.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 599ms/step - categorical_accuracy: 0.9762 - loss: 0.0642 - val_categorical_accuracy: 0.9595 - val_loss: 0.1388 - learning_rate: 9.5367e-11\nEpoch 2/52\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9797 - loss: 0.0691\nEpoch 2: val_loss did not improve from 0.13880\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9797 - loss: 0.0691 - val_categorical_accuracy: 0.9306 - val_loss: 0.2205 - learning_rate: 9.5367e-11\nEpoch 3/52\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9761 - loss: 0.0815\nEpoch 3: val_loss did not improve from 0.13880\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9762 - loss: 0.0812 - val_categorical_accuracy: 0.9451 - val_loss: 0.2063 - learning_rate: 9.5367e-11\nEpoch 4/52\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9728 - loss: 0.0793\nEpoch 4: val_loss did not improve from 0.13880\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9728 - loss: 0.0793 - val_categorical_accuracy: 0.9595 - val_loss: 0.1483 - learning_rate: 9.5367e-11\nEpoch 5/52\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9780 - loss: 0.0680\nEpoch 5: val_loss did not improve from 0.13880\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9780 - loss: 0.0681 - val_categorical_accuracy: 0.9595 - val_loss: 0.1499 - learning_rate: 9.5367e-11\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 49).\nRestarting from last best val_loss at local epoch 0 (global epoch 45).\nEpoch 1/51\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - categorical_accuracy: 0.9791 - loss: 0.0631\nEpoch 1: val_loss improved from inf to 0.17056, saving model to ./output/lastbest-21.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 595ms/step - categorical_accuracy: 0.9791 - loss: 0.0632 - val_categorical_accuracy: 0.9509 - val_loss: 0.1706 - learning_rate: 4.7684e-11\nEpoch 2/51\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - categorical_accuracy: 0.9745 - loss: 0.0665\nEpoch 2: val_loss did not improve from 0.17056\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9744 - loss: 0.0666 - val_categorical_accuracy: 0.9422 - val_loss: 0.1753 - learning_rate: 4.7684e-11\nEpoch 3/51\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - categorical_accuracy: 0.9735 - loss: 0.0696\nEpoch 3: val_loss did not improve from 0.17056\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9735 - loss: 0.0696 - val_categorical_accuracy: 0.9422 - val_loss: 0.1918 - learning_rate: 4.7684e-11\nEpoch 4/51\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9781 - loss: 0.0865\nEpoch 4: val_loss did not improve from 0.17056\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 526ms/step - categorical_accuracy: 0.9781 - loss: 0.0863 - val_categorical_accuracy: 0.9364 - val_loss: 0.1741 - learning_rate: 4.7684e-11\nEpoch 5/51\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9813 - loss: 0.0564\nEpoch 5: val_loss improved from 0.17056 to 0.14422, saving model to ./output/lastbest-21.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 555ms/step - categorical_accuracy: 0.9813 - loss: 0.0567 - val_categorical_accuracy: 0.9480 - val_loss: 0.1442 - learning_rate: 4.7684e-11\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 50).\nRestarting from last best val_loss at local epoch 0 (global epoch 46).\nEpoch 1/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - categorical_accuracy: 0.9765 - loss: 0.0766\nEpoch 1: val_loss improved from inf to 0.12878, saving model to ./output/lastbest-22.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 598ms/step - categorical_accuracy: 0.9765 - loss: 0.0765 - val_categorical_accuracy: 0.9451 - val_loss: 0.1288 - learning_rate: 2.3842e-11\nEpoch 2/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9770 - loss: 0.0769\nEpoch 2: val_loss did not improve from 0.12878\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9770 - loss: 0.0769 - val_categorical_accuracy: 0.9538 - val_loss: 0.1705 - learning_rate: 2.3842e-11\nEpoch 3/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - categorical_accuracy: 0.9794 - loss: 0.0730\nEpoch 3: val_loss did not improve from 0.12878\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - categorical_accuracy: 0.9793 - loss: 0.0729 - val_categorical_accuracy: 0.9393 - val_loss: 0.1753 - learning_rate: 2.3842e-11\nEpoch 4/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - categorical_accuracy: 0.9823 - loss: 0.0541\nEpoch 4: val_loss did not improve from 0.12878\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 519ms/step - categorical_accuracy: 0.9823 - loss: 0.0543 - val_categorical_accuracy: 0.9480 - val_loss: 0.1640 - learning_rate: 2.3842e-11\nEpoch 5/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9778 - loss: 0.0644\nEpoch 5: val_loss improved from 0.12878 to 0.12047, saving model to ./output/lastbest-22.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - categorical_accuracy: 0.9778 - loss: 0.0645 - val_categorical_accuracy: 0.9624 - val_loss: 0.1205 - learning_rate: 2.3842e-11\nEpoch 6/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - categorical_accuracy: 0.9773 - loss: 0.0685\nEpoch 6: val_loss did not improve from 0.12047\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9773 - loss: 0.0686 - val_categorical_accuracy: 0.9451 - val_loss: 0.1747 - learning_rate: 2.3842e-11\nEpoch 7/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9740 - loss: 0.0817\nEpoch 7: val_loss did not improve from 0.12047\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9741 - loss: 0.0815 - val_categorical_accuracy: 0.9509 - val_loss: 0.1863 - learning_rate: 2.3842e-11\nEpoch 8/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9810 - loss: 0.0625\nEpoch 8: val_loss did not improve from 0.12047\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9810 - loss: 0.0626 - val_categorical_accuracy: 0.9393 - val_loss: 0.1520 - learning_rate: 2.3842e-11\nEpoch 9/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9761 - loss: 0.0750\nEpoch 9: val_loss did not improve from 0.12047\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9761 - loss: 0.0749 - val_categorical_accuracy: 0.9538 - val_loss: 0.1453 - learning_rate: 2.3842e-11\nEpoch 10/50\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - categorical_accuracy: 0.9802 - loss: 0.0604\nEpoch 10: val_loss did not improve from 0.12047\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9802 - loss: 0.0604 - val_categorical_accuracy: 0.9451 - val_loss: 0.1586 - learning_rate: 2.3842e-11\nEpoch 10: early stopping\nRestoring model weights from the end of the best epoch: 5.\nEarly stopping triggered after local epoch 9 (global epoch 56).\nRestarting from last best val_loss at local epoch 5 (global epoch 52).\nEpoch 1/44\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - categorical_accuracy: 0.9689 - loss: 0.0824\nEpoch 1: val_loss improved from inf to 0.16794, saving model to ./output/lastbest-23.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 588ms/step - categorical_accuracy: 0.9690 - loss: 0.0823 - val_categorical_accuracy: 0.9451 - val_loss: 0.1679 - learning_rate: 1.1921e-11\nEpoch 2/44\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9764 - loss: 0.0665\nEpoch 2: val_loss improved from 0.16794 to 0.15546, saving model to ./output/lastbest-23.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 549ms/step - categorical_accuracy: 0.9765 - loss: 0.0665 - val_categorical_accuracy: 0.9566 - val_loss: 0.1555 - learning_rate: 1.1921e-11\nEpoch 3/44\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9827 - loss: 0.0652\nEpoch 3: val_loss did not improve from 0.15546\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9826 - loss: 0.0652 - val_categorical_accuracy: 0.9422 - val_loss: 0.1848 - learning_rate: 1.1921e-11\nEpoch 4/44\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9752 - loss: 0.0668\nEpoch 4: val_loss did not improve from 0.15546\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9751 - loss: 0.0669 - val_categorical_accuracy: 0.9538 - val_loss: 0.1650 - learning_rate: 1.1921e-11\nEpoch 5/44\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9768 - loss: 0.0707\nEpoch 5: val_loss did not improve from 0.15546\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 533ms/step - categorical_accuracy: 0.9768 - loss: 0.0706 - val_categorical_accuracy: 0.9393 - val_loss: 0.1752 - learning_rate: 1.1921e-11\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 57).\nRestarting from last best val_loss at local epoch 0 (global epoch 53).\nEpoch 1/43\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - categorical_accuracy: 0.9819 - loss: 0.0645\nEpoch 1: val_loss improved from inf to 0.16419, saving model to ./output/lastbest-24.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 588ms/step - categorical_accuracy: 0.9819 - loss: 0.0646 - val_categorical_accuracy: 0.9566 - val_loss: 0.1642 - learning_rate: 5.9605e-12\nEpoch 2/43\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - categorical_accuracy: 0.9787 - loss: 0.0830\nEpoch 2: val_loss improved from 0.16419 to 0.15501, saving model to ./output/lastbest-24.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 541ms/step - categorical_accuracy: 0.9787 - loss: 0.0829 - val_categorical_accuracy: 0.9364 - val_loss: 0.1550 - learning_rate: 5.9605e-12\nEpoch 3/43\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9823 - loss: 0.0678\nEpoch 3: val_loss did not improve from 0.15501\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9822 - loss: 0.0679 - val_categorical_accuracy: 0.9480 - val_loss: 0.1637 - learning_rate: 5.9605e-12\nEpoch 4/43\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9773 - loss: 0.0667\nEpoch 4: val_loss did not improve from 0.15501\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 522ms/step - categorical_accuracy: 0.9773 - loss: 0.0668 - val_categorical_accuracy: 0.9422 - val_loss: 0.1900 - learning_rate: 5.9605e-12\nEpoch 5/43\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - categorical_accuracy: 0.9804 - loss: 0.0703\nEpoch 5: val_loss did not improve from 0.15501\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 522ms/step - categorical_accuracy: 0.9803 - loss: 0.0705 - val_categorical_accuracy: 0.9422 - val_loss: 0.1721 - learning_rate: 5.9605e-12\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 58).\nRestarting from last best val_loss at local epoch 0 (global epoch 54).\nEpoch 1/42\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - categorical_accuracy: 0.9795 - loss: 0.0668\nEpoch 1: val_loss improved from inf to 0.15245, saving model to ./output/lastbest-25.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 589ms/step - categorical_accuracy: 0.9795 - loss: 0.0669 - val_categorical_accuracy: 0.9538 - val_loss: 0.1525 - learning_rate: 2.9802e-12\nEpoch 2/42\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - categorical_accuracy: 0.9843 - loss: 0.0603\nEpoch 2: val_loss did not improve from 0.15245\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 539ms/step - categorical_accuracy: 0.9843 - loss: 0.0604 - val_categorical_accuracy: 0.9451 - val_loss: 0.1812 - learning_rate: 2.9802e-12\nEpoch 3/42\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9829 - loss: 0.0636\nEpoch 3: val_loss did not improve from 0.15245\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9828 - loss: 0.0637 - val_categorical_accuracy: 0.9451 - val_loss: 0.1728 - learning_rate: 2.9802e-12\nEpoch 4/42\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9762 - loss: 0.0647\nEpoch 4: val_loss improved from 0.15245 to 0.15170, saving model to ./output/lastbest-25.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - categorical_accuracy: 0.9762 - loss: 0.0647 - val_categorical_accuracy: 0.9538 - val_loss: 0.1517 - learning_rate: 2.9802e-12\nEpoch 5/42\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9821 - loss: 0.0634\nEpoch 5: val_loss did not improve from 0.15170\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9821 - loss: 0.0635 - val_categorical_accuracy: 0.9393 - val_loss: 0.1696 - learning_rate: 2.9802e-12\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 59).\nRestarting from last best val_loss at local epoch 0 (global epoch 55).\nEpoch 1/41\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - categorical_accuracy: 0.9776 - loss: 0.0616\nEpoch 1: val_loss improved from inf to 0.16304, saving model to ./output/lastbest-26.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 600ms/step - categorical_accuracy: 0.9775 - loss: 0.0618 - val_categorical_accuracy: 0.9595 - val_loss: 0.1630 - learning_rate: 1.4901e-12\nEpoch 2/41\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9721 - loss: 0.0733\nEpoch 2: val_loss did not improve from 0.16304\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9722 - loss: 0.0733 - val_categorical_accuracy: 0.9422 - val_loss: 0.1736 - learning_rate: 1.4901e-12\nEpoch 3/41\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9787 - loss: 0.0755\nEpoch 3: val_loss improved from 0.16304 to 0.13987, saving model to ./output/lastbest-26.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 549ms/step - categorical_accuracy: 0.9786 - loss: 0.0756 - val_categorical_accuracy: 0.9480 - val_loss: 0.1399 - learning_rate: 1.4901e-12\nEpoch 4/41\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9870 - loss: 0.0518\nEpoch 4: val_loss did not improve from 0.13987\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 536ms/step - categorical_accuracy: 0.9869 - loss: 0.0521 - val_categorical_accuracy: 0.9538 - val_loss: 0.1483 - learning_rate: 1.4901e-12\nEpoch 5/41\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9782 - loss: 0.0645\nEpoch 5: val_loss did not improve from 0.13987\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9782 - loss: 0.0646 - val_categorical_accuracy: 0.9624 - val_loss: 0.1523 - learning_rate: 1.4901e-12\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 60).\nRestarting from last best val_loss at local epoch 0 (global epoch 56).\nEpoch 1/40\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - categorical_accuracy: 0.9795 - loss: 0.0781\nEpoch 1: val_loss improved from inf to 0.16277, saving model to ./output/lastbest-27.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 593ms/step - categorical_accuracy: 0.9795 - loss: 0.0779 - val_categorical_accuracy: 0.9480 - val_loss: 0.1628 - learning_rate: 7.4506e-13\nEpoch 2/40\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9814 - loss: 0.0692\nEpoch 2: val_loss did not improve from 0.16277\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9813 - loss: 0.0693 - val_categorical_accuracy: 0.9480 - val_loss: 0.1865 - learning_rate: 7.4506e-13\nEpoch 3/40\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - categorical_accuracy: 0.9804 - loss: 0.0602\nEpoch 3: val_loss improved from 0.16277 to 0.15631, saving model to ./output/lastbest-27.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 539ms/step - categorical_accuracy: 0.9803 - loss: 0.0604 - val_categorical_accuracy: 0.9422 - val_loss: 0.1563 - learning_rate: 7.4506e-13\nEpoch 4/40\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9772 - loss: 0.0730\nEpoch 4: val_loss did not improve from 0.15631\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9772 - loss: 0.0730 - val_categorical_accuracy: 0.9480 - val_loss: 0.1928 - learning_rate: 7.4506e-13\nEpoch 5/40\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - categorical_accuracy: 0.9793 - loss: 0.0700\nEpoch 5: val_loss did not improve from 0.15631\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9793 - loss: 0.0700 - val_categorical_accuracy: 0.9480 - val_loss: 0.1812 - learning_rate: 7.4506e-13\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 61).\nRestarting from last best val_loss at local epoch 0 (global epoch 57).\nEpoch 1/39\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - categorical_accuracy: 0.9817 - loss: 0.0693\nEpoch 1: val_loss improved from inf to 0.14962, saving model to ./output/lastbest-28.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 589ms/step - categorical_accuracy: 0.9816 - loss: 0.0694 - val_categorical_accuracy: 0.9538 - val_loss: 0.1496 - learning_rate: 3.7253e-13\nEpoch 2/39\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9734 - loss: 0.0828\nEpoch 2: val_loss did not improve from 0.14962\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9735 - loss: 0.0825 - val_categorical_accuracy: 0.9393 - val_loss: 0.1856 - learning_rate: 3.7253e-13\nEpoch 3/39\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - categorical_accuracy: 0.9839 - loss: 0.0619\nEpoch 3: val_loss did not improve from 0.14962\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 526ms/step - categorical_accuracy: 0.9839 - loss: 0.0619 - val_categorical_accuracy: 0.9480 - val_loss: 0.1635 - learning_rate: 3.7253e-13\nEpoch 4/39\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9773 - loss: 0.0788\nEpoch 4: val_loss did not improve from 0.14962\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9773 - loss: 0.0787 - val_categorical_accuracy: 0.9393 - val_loss: 0.1643 - learning_rate: 3.7253e-13\nEpoch 5/39\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9709 - loss: 0.0862\nEpoch 5: val_loss did not improve from 0.14962\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9709 - loss: 0.0861 - val_categorical_accuracy: 0.9393 - val_loss: 0.2011 - learning_rate: 3.7253e-13\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 62).\nRestarting from last best val_loss at local epoch 0 (global epoch 58).\nEpoch 1/38\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - categorical_accuracy: 0.9791 - loss: 0.0838\nEpoch 1: val_loss improved from inf to 0.15108, saving model to ./output/lastbest-29.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 599ms/step - categorical_accuracy: 0.9792 - loss: 0.0834 - val_categorical_accuracy: 0.9480 - val_loss: 0.1511 - learning_rate: 1.8626e-13\nEpoch 2/38\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9792 - loss: 0.0565\nEpoch 2: val_loss did not improve from 0.15108\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 536ms/step - categorical_accuracy: 0.9792 - loss: 0.0567 - val_categorical_accuracy: 0.9538 - val_loss: 0.1615 - learning_rate: 1.8626e-13\nEpoch 3/38\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9741 - loss: 0.0792\nEpoch 3: val_loss did not improve from 0.15108\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 533ms/step - categorical_accuracy: 0.9742 - loss: 0.0790 - val_categorical_accuracy: 0.9393 - val_loss: 0.1544 - learning_rate: 1.8626e-13\nEpoch 4/38\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9831 - loss: 0.0616\nEpoch 4: val_loss did not improve from 0.15108\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 537ms/step - categorical_accuracy: 0.9831 - loss: 0.0617 - val_categorical_accuracy: 0.9451 - val_loss: 0.1723 - learning_rate: 1.8626e-13\nEpoch 5/38\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9806 - loss: 0.0624\nEpoch 5: val_loss did not improve from 0.15108\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9806 - loss: 0.0624 - val_categorical_accuracy: 0.9509 - val_loss: 0.1947 - learning_rate: 1.8626e-13\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 63).\nRestarting from last best val_loss at local epoch 0 (global epoch 59).\nEpoch 1/37\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - categorical_accuracy: 0.9828 - loss: 0.0664\nEpoch 1: val_loss improved from inf to 0.14635, saving model to ./output/lastbest-30.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 595ms/step - categorical_accuracy: 0.9827 - loss: 0.0664 - val_categorical_accuracy: 0.9595 - val_loss: 0.1463 - learning_rate: 9.3132e-14\nEpoch 2/37\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9756 - loss: 0.0702\nEpoch 2: val_loss did not improve from 0.14635\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9756 - loss: 0.0703 - val_categorical_accuracy: 0.9595 - val_loss: 0.1535 - learning_rate: 9.3132e-14\nEpoch 3/37\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9716 - loss: 0.0890\nEpoch 3: val_loss did not improve from 0.14635\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9716 - loss: 0.0888 - val_categorical_accuracy: 0.9451 - val_loss: 0.1673 - learning_rate: 9.3132e-14\nEpoch 4/37\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9793 - loss: 0.0773\nEpoch 4: val_loss improved from 0.14635 to 0.13704, saving model to ./output/lastbest-30.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - categorical_accuracy: 0.9793 - loss: 0.0772 - val_categorical_accuracy: 0.9595 - val_loss: 0.1370 - learning_rate: 9.3132e-14\nEpoch 5/37\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9763 - loss: 0.0794\nEpoch 5: val_loss did not improve from 0.13704\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - categorical_accuracy: 0.9764 - loss: 0.0793 - val_categorical_accuracy: 0.9509 - val_loss: 0.1657 - learning_rate: 9.3132e-14\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 64).\nRestarting from last best val_loss at local epoch 0 (global epoch 60).\nEpoch 1/36\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - categorical_accuracy: 0.9836 - loss: 0.0561\nEpoch 1: val_loss improved from inf to 0.13401, saving model to ./output/lastbest-31.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 586ms/step - categorical_accuracy: 0.9836 - loss: 0.0563 - val_categorical_accuracy: 0.9566 - val_loss: 0.1340 - learning_rate: 4.6566e-14\nEpoch 2/36\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9746 - loss: 0.0796\nEpoch 2: val_loss did not improve from 0.13401\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9746 - loss: 0.0795 - val_categorical_accuracy: 0.9364 - val_loss: 0.1911 - learning_rate: 4.6566e-14\nEpoch 3/36\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9763 - loss: 0.0718\nEpoch 3: val_loss did not improve from 0.13401\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9763 - loss: 0.0719 - val_categorical_accuracy: 0.9480 - val_loss: 0.1697 - learning_rate: 4.6566e-14\nEpoch 4/36\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9804 - loss: 0.0574\nEpoch 4: val_loss did not improve from 0.13401\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - categorical_accuracy: 0.9803 - loss: 0.0575 - val_categorical_accuracy: 0.9509 - val_loss: 0.1800 - learning_rate: 4.6566e-14\nEpoch 5/36\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9797 - loss: 0.0616\nEpoch 5: val_loss did not improve from 0.13401\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9797 - loss: 0.0617 - val_categorical_accuracy: 0.9306 - val_loss: 0.1886 - learning_rate: 4.6566e-14\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 65).\nRestarting from last best val_loss at local epoch 0 (global epoch 61).\nEpoch 1/35\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - categorical_accuracy: 0.9812 - loss: 0.0625\nEpoch 1: val_loss improved from inf to 0.17128, saving model to ./output/lastbest-32.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 603ms/step - categorical_accuracy: 0.9811 - loss: 0.0625 - val_categorical_accuracy: 0.9538 - val_loss: 0.1713 - learning_rate: 2.3283e-14\nEpoch 2/35\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - categorical_accuracy: 0.9817 - loss: 0.0650\nEpoch 2: val_loss did not improve from 0.17128\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 526ms/step - categorical_accuracy: 0.9817 - loss: 0.0651 - val_categorical_accuracy: 0.9451 - val_loss: 0.1726 - learning_rate: 2.3283e-14\nEpoch 3/35\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9801 - loss: 0.0677\nEpoch 3: val_loss improved from 0.17128 to 0.15229, saving model to ./output/lastbest-32.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9801 - loss: 0.0677 - val_categorical_accuracy: 0.9422 - val_loss: 0.1523 - learning_rate: 2.3283e-14\nEpoch 4/35\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9782 - loss: 0.0682\nEpoch 4: val_loss did not improve from 0.15229\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9782 - loss: 0.0682 - val_categorical_accuracy: 0.9538 - val_loss: 0.1536 - learning_rate: 2.3283e-14\nEpoch 5/35\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9817 - loss: 0.0657\nEpoch 5: val_loss did not improve from 0.15229\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 533ms/step - categorical_accuracy: 0.9816 - loss: 0.0658 - val_categorical_accuracy: 0.9538 - val_loss: 0.1588 - learning_rate: 2.3283e-14\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 66).\nRestarting from last best val_loss at local epoch 0 (global epoch 62).\nEpoch 1/34\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - categorical_accuracy: 0.9821 - loss: 0.0750\nEpoch 1: val_loss improved from inf to 0.14446, saving model to ./output/lastbest-33.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 592ms/step - categorical_accuracy: 0.9821 - loss: 0.0749 - val_categorical_accuracy: 0.9566 - val_loss: 0.1445 - learning_rate: 1.1642e-14\nEpoch 2/34\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9772 - loss: 0.0794\nEpoch 2: val_loss improved from 0.14446 to 0.12618, saving model to ./output/lastbest-33.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - categorical_accuracy: 0.9772 - loss: 0.0793 - val_categorical_accuracy: 0.9624 - val_loss: 0.1262 - learning_rate: 1.1642e-14\nEpoch 3/34\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9744 - loss: 0.0724\nEpoch 3: val_loss did not improve from 0.12618\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9744 - loss: 0.0723 - val_categorical_accuracy: 0.9393 - val_loss: 0.1886 - learning_rate: 1.1642e-14\nEpoch 4/34\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9737 - loss: 0.0798\nEpoch 4: val_loss did not improve from 0.12618\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9738 - loss: 0.0797 - val_categorical_accuracy: 0.9393 - val_loss: 0.1995 - learning_rate: 1.1642e-14\nEpoch 5/34\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9741 - loss: 0.0810\nEpoch 5: val_loss did not improve from 0.12618\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 536ms/step - categorical_accuracy: 0.9742 - loss: 0.0808 - val_categorical_accuracy: 0.9364 - val_loss: 0.1837 - learning_rate: 1.1642e-14\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 67).\nRestarting from last best val_loss at local epoch 0 (global epoch 63).\nEpoch 1/33\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - categorical_accuracy: 0.9826 - loss: 0.0571\nEpoch 1: val_loss improved from inf to 0.16882, saving model to ./output/lastbest-34.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 596ms/step - categorical_accuracy: 0.9826 - loss: 0.0572 - val_categorical_accuracy: 0.9509 - val_loss: 0.1688 - learning_rate: 5.8208e-15\nEpoch 2/33\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9755 - loss: 0.0731\nEpoch 2: val_loss improved from 0.16882 to 0.15157, saving model to ./output/lastbest-34.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - categorical_accuracy: 0.9756 - loss: 0.0729 - val_categorical_accuracy: 0.9451 - val_loss: 0.1516 - learning_rate: 5.8208e-15\nEpoch 3/33\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - categorical_accuracy: 0.9722 - loss: 0.0764\nEpoch 3: val_loss did not improve from 0.15157\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 537ms/step - categorical_accuracy: 0.9722 - loss: 0.0764 - val_categorical_accuracy: 0.9538 - val_loss: 0.1517 - learning_rate: 5.8208e-15\nEpoch 4/33\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9745 - loss: 0.0796\nEpoch 4: val_loss did not improve from 0.15157\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9746 - loss: 0.0795 - val_categorical_accuracy: 0.9480 - val_loss: 0.1536 - learning_rate: 5.8208e-15\nEpoch 5/33\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - categorical_accuracy: 0.9825 - loss: 0.0695\nEpoch 5: val_loss improved from 0.15157 to 0.14081, saving model to ./output/lastbest-34.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 541ms/step - categorical_accuracy: 0.9825 - loss: 0.0694 - val_categorical_accuracy: 0.9566 - val_loss: 0.1408 - learning_rate: 5.8208e-15\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 68).\nRestarting from last best val_loss at local epoch 0 (global epoch 64).\nEpoch 1/32\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - categorical_accuracy: 0.9727 - loss: 0.0781\nEpoch 1: val_loss improved from inf to 0.15322, saving model to ./output/lastbest-35.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 598ms/step - categorical_accuracy: 0.9727 - loss: 0.0781 - val_categorical_accuracy: 0.9538 - val_loss: 0.1532 - learning_rate: 2.9104e-15\nEpoch 2/32\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - categorical_accuracy: 0.9816 - loss: 0.0646\nEpoch 2: val_loss improved from 0.15322 to 0.13343, saving model to ./output/lastbest-35.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 550ms/step - categorical_accuracy: 0.9815 - loss: 0.0647 - val_categorical_accuracy: 0.9509 - val_loss: 0.1334 - learning_rate: 2.9104e-15\nEpoch 3/32\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9772 - loss: 0.0702\nEpoch 3: val_loss did not improve from 0.13343\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9772 - loss: 0.0702 - val_categorical_accuracy: 0.9422 - val_loss: 0.1882 - learning_rate: 2.9104e-15\nEpoch 4/32\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9765 - loss: 0.0801\nEpoch 4: val_loss did not improve from 0.13343\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9766 - loss: 0.0800 - val_categorical_accuracy: 0.9451 - val_loss: 0.1683 - learning_rate: 2.9104e-15\nEpoch 5/32\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9790 - loss: 0.0747\nEpoch 5: val_loss did not improve from 0.13343\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9789 - loss: 0.0747 - val_categorical_accuracy: 0.9335 - val_loss: 0.2013 - learning_rate: 2.9104e-15\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 69).\nRestarting from last best val_loss at local epoch 0 (global epoch 65).\nEpoch 1/31\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - categorical_accuracy: 0.9745 - loss: 0.0699\nEpoch 1: val_loss improved from inf to 0.15093, saving model to ./output/lastbest-36.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 591ms/step - categorical_accuracy: 0.9745 - loss: 0.0700 - val_categorical_accuracy: 0.9509 - val_loss: 0.1509 - learning_rate: 1.4552e-15\nEpoch 2/31\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - categorical_accuracy: 0.9738 - loss: 0.0767\nEpoch 2: val_loss did not improve from 0.15093\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 522ms/step - categorical_accuracy: 0.9739 - loss: 0.0766 - val_categorical_accuracy: 0.9451 - val_loss: 0.1510 - learning_rate: 1.4552e-15\nEpoch 3/31\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9811 - loss: 0.0619\nEpoch 3: val_loss did not improve from 0.15093\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9811 - loss: 0.0620 - val_categorical_accuracy: 0.9480 - val_loss: 0.1679 - learning_rate: 1.4552e-15\nEpoch 4/31\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9786 - loss: 0.0740\nEpoch 4: val_loss did not improve from 0.15093\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9786 - loss: 0.0739 - val_categorical_accuracy: 0.9480 - val_loss: 0.1811 - learning_rate: 1.4552e-15\nEpoch 5/31\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9688 - loss: 0.0996\nEpoch 5: val_loss improved from 0.15093 to 0.15062, saving model to ./output/lastbest-36.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - categorical_accuracy: 0.9690 - loss: 0.0992 - val_categorical_accuracy: 0.9566 - val_loss: 0.1506 - learning_rate: 1.4552e-15\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 70).\nRestarting from last best val_loss at local epoch 0 (global epoch 66).\nEpoch 1/30\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - categorical_accuracy: 0.9790 - loss: 0.0639\nEpoch 1: val_loss improved from inf to 0.17770, saving model to ./output/lastbest-37.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 596ms/step - categorical_accuracy: 0.9790 - loss: 0.0640 - val_categorical_accuracy: 0.9451 - val_loss: 0.1777 - learning_rate: 7.2760e-16\nEpoch 2/30\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9810 - loss: 0.0670\nEpoch 2: val_loss improved from 0.17770 to 0.16642, saving model to ./output/lastbest-37.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 550ms/step - categorical_accuracy: 0.9810 - loss: 0.0670 - val_categorical_accuracy: 0.9480 - val_loss: 0.1664 - learning_rate: 7.2760e-16\nEpoch 3/30\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9824 - loss: 0.0614\nEpoch 3: val_loss did not improve from 0.16642\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9823 - loss: 0.0615 - val_categorical_accuracy: 0.9422 - val_loss: 0.1740 - learning_rate: 7.2760e-16\nEpoch 4/30\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9752 - loss: 0.0649\nEpoch 4: val_loss improved from 0.16642 to 0.15920, saving model to ./output/lastbest-37.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 542ms/step - categorical_accuracy: 0.9753 - loss: 0.0650 - val_categorical_accuracy: 0.9566 - val_loss: 0.1592 - learning_rate: 7.2760e-16\nEpoch 5/30\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9814 - loss: 0.0733\nEpoch 5: val_loss did not improve from 0.15920\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9814 - loss: 0.0732 - val_categorical_accuracy: 0.9566 - val_loss: 0.1596 - learning_rate: 7.2760e-16\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 71).\nRestarting from last best val_loss at local epoch 0 (global epoch 67).\nEpoch 1/29\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - categorical_accuracy: 0.9731 - loss: 0.0771\nEpoch 1: val_loss improved from inf to 0.16237, saving model to ./output/lastbest-38.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 590ms/step - categorical_accuracy: 0.9731 - loss: 0.0770 - val_categorical_accuracy: 0.9566 - val_loss: 0.1624 - learning_rate: 3.6380e-16\nEpoch 2/29\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - categorical_accuracy: 0.9794 - loss: 0.0885\nEpoch 2: val_loss did not improve from 0.16237\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9794 - loss: 0.0883 - val_categorical_accuracy: 0.9451 - val_loss: 0.1839 - learning_rate: 3.6380e-16\nEpoch 3/29\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9749 - loss: 0.0641\nEpoch 3: val_loss did not improve from 0.16237\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 533ms/step - categorical_accuracy: 0.9749 - loss: 0.0642 - val_categorical_accuracy: 0.9306 - val_loss: 0.1847 - learning_rate: 3.6380e-16\nEpoch 4/29\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - categorical_accuracy: 0.9823 - loss: 0.0619\nEpoch 4: val_loss improved from 0.16237 to 0.15543, saving model to ./output/lastbest-38.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - categorical_accuracy: 0.9823 - loss: 0.0620 - val_categorical_accuracy: 0.9480 - val_loss: 0.1554 - learning_rate: 3.6380e-16\nEpoch 5/29\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - categorical_accuracy: 0.9814 - loss: 0.0684\nEpoch 5: val_loss did not improve from 0.15543\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 522ms/step - categorical_accuracy: 0.9813 - loss: 0.0685 - val_categorical_accuracy: 0.9422 - val_loss: 0.1594 - learning_rate: 3.6380e-16\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 72).\nRestarting from last best val_loss at local epoch 0 (global epoch 68).\nEpoch 1/28\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - categorical_accuracy: 0.9814 - loss: 0.0716\nEpoch 1: val_loss improved from inf to 0.17712, saving model to ./output/lastbest-39.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 598ms/step - categorical_accuracy: 0.9814 - loss: 0.0715 - val_categorical_accuracy: 0.9509 - val_loss: 0.1771 - learning_rate: 1.8190e-16\nEpoch 2/28\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9771 - loss: 0.0694\nEpoch 2: val_loss improved from 0.17712 to 0.16676, saving model to ./output/lastbest-39.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 543ms/step - categorical_accuracy: 0.9771 - loss: 0.0694 - val_categorical_accuracy: 0.9364 - val_loss: 0.1668 - learning_rate: 1.8190e-16\nEpoch 3/28\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9723 - loss: 0.0765\nEpoch 3: val_loss did not improve from 0.16676\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - categorical_accuracy: 0.9723 - loss: 0.0764 - val_categorical_accuracy: 0.9306 - val_loss: 0.2197 - learning_rate: 1.8190e-16\nEpoch 4/28\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9805 - loss: 0.0645\nEpoch 4: val_loss did not improve from 0.16676\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9804 - loss: 0.0647 - val_categorical_accuracy: 0.9509 - val_loss: 0.1733 - learning_rate: 1.8190e-16\nEpoch 5/28\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9752 - loss: 0.0660\nEpoch 5: val_loss did not improve from 0.16676\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 523ms/step - categorical_accuracy: 0.9752 - loss: 0.0662 - val_categorical_accuracy: 0.9480 - val_loss: 0.1716 - learning_rate: 1.8190e-16\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 73).\nRestarting from last best val_loss at local epoch 0 (global epoch 69).\nEpoch 1/27\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - categorical_accuracy: 0.9767 - loss: 0.0715\nEpoch 1: val_loss improved from inf to 0.16801, saving model to ./output/lastbest-40.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 599ms/step - categorical_accuracy: 0.9767 - loss: 0.0714 - val_categorical_accuracy: 0.9538 - val_loss: 0.1680 - learning_rate: 9.0949e-17\nEpoch 2/27\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9825 - loss: 0.0714\nEpoch 2: val_loss improved from 0.16801 to 0.15516, saving model to ./output/lastbest-40.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9825 - loss: 0.0714 - val_categorical_accuracy: 0.9451 - val_loss: 0.1552 - learning_rate: 9.0949e-17\nEpoch 3/27\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9795 - loss: 0.0681\nEpoch 3: val_loss did not improve from 0.15516\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - categorical_accuracy: 0.9794 - loss: 0.0682 - val_categorical_accuracy: 0.9451 - val_loss: 0.1590 - learning_rate: 9.0949e-17\nEpoch 4/27\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9802 - loss: 0.0624\nEpoch 4: val_loss did not improve from 0.15516\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9801 - loss: 0.0624 - val_categorical_accuracy: 0.9451 - val_loss: 0.1759 - learning_rate: 9.0949e-17\nEpoch 5/27\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9722 - loss: 0.0813\nEpoch 5: val_loss improved from 0.15516 to 0.14011, saving model to ./output/lastbest-40.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9722 - loss: 0.0812 - val_categorical_accuracy: 0.9451 - val_loss: 0.1401 - learning_rate: 9.0949e-17\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 74).\nRestarting from last best val_loss at local epoch 0 (global epoch 70).\nEpoch 1/26\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - categorical_accuracy: 0.9784 - loss: 0.0725\nEpoch 1: val_loss improved from inf to 0.14481, saving model to ./output/lastbest-41.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 594ms/step - categorical_accuracy: 0.9784 - loss: 0.0725 - val_categorical_accuracy: 0.9451 - val_loss: 0.1448 - learning_rate: 4.5475e-17\nEpoch 2/26\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9810 - loss: 0.0661\nEpoch 2: val_loss improved from 0.14481 to 0.14457, saving model to ./output/lastbest-41.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9810 - loss: 0.0662 - val_categorical_accuracy: 0.9422 - val_loss: 0.1446 - learning_rate: 4.5475e-17\nEpoch 3/26\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9756 - loss: 0.0867\nEpoch 3: val_loss did not improve from 0.14457\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9757 - loss: 0.0864 - val_categorical_accuracy: 0.9509 - val_loss: 0.1934 - learning_rate: 4.5475e-17\nEpoch 4/26\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9743 - loss: 0.0790\nEpoch 4: val_loss did not improve from 0.14457\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9743 - loss: 0.0789 - val_categorical_accuracy: 0.9509 - val_loss: 0.1518 - learning_rate: 4.5475e-17\nEpoch 5/26\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - categorical_accuracy: 0.9845 - loss: 0.0576\nEpoch 5: val_loss did not improve from 0.14457\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 540ms/step - categorical_accuracy: 0.9844 - loss: 0.0577 - val_categorical_accuracy: 0.9422 - val_loss: 0.1453 - learning_rate: 4.5475e-17\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 75).\nRestarting from last best val_loss at local epoch 0 (global epoch 71).\nEpoch 1/25\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - categorical_accuracy: 0.9821 - loss: 0.0638\nEpoch 1: val_loss improved from inf to 0.16823, saving model to ./output/lastbest-42.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 595ms/step - categorical_accuracy: 0.9820 - loss: 0.0638 - val_categorical_accuracy: 0.9538 - val_loss: 0.1682 - learning_rate: 2.2737e-17\nEpoch 2/25\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9717 - loss: 0.0806\nEpoch 2: val_loss improved from 0.16823 to 0.15300, saving model to ./output/lastbest-42.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 551ms/step - categorical_accuracy: 0.9717 - loss: 0.0805 - val_categorical_accuracy: 0.9480 - val_loss: 0.1530 - learning_rate: 2.2737e-17\nEpoch 3/25\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9775 - loss: 0.0616\nEpoch 3: val_loss improved from 0.15300 to 0.13711, saving model to ./output/lastbest-42.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 554ms/step - categorical_accuracy: 0.9775 - loss: 0.0617 - val_categorical_accuracy: 0.9480 - val_loss: 0.1371 - learning_rate: 2.2737e-17\nEpoch 4/25\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9781 - loss: 0.0705\nEpoch 4: val_loss did not improve from 0.13711\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9781 - loss: 0.0705 - val_categorical_accuracy: 0.9509 - val_loss: 0.1507 - learning_rate: 2.2737e-17\nEpoch 5/25\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9777 - loss: 0.0757\nEpoch 5: val_loss improved from 0.13711 to 0.13484, saving model to ./output/lastbest-42.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 551ms/step - categorical_accuracy: 0.9777 - loss: 0.0755 - val_categorical_accuracy: 0.9480 - val_loss: 0.1348 - learning_rate: 2.2737e-17\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 76).\nRestarting from last best val_loss at local epoch 0 (global epoch 72).\nEpoch 1/24\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - categorical_accuracy: 0.9761 - loss: 0.0615\nEpoch 1: val_loss improved from inf to 0.15499, saving model to ./output/lastbest-43.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 596ms/step - categorical_accuracy: 0.9761 - loss: 0.0616 - val_categorical_accuracy: 0.9509 - val_loss: 0.1550 - learning_rate: 1.1369e-17\nEpoch 2/24\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - categorical_accuracy: 0.9802 - loss: 0.0584\nEpoch 2: val_loss did not improve from 0.15499\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 521ms/step - categorical_accuracy: 0.9801 - loss: 0.0587 - val_categorical_accuracy: 0.9451 - val_loss: 0.1561 - learning_rate: 1.1369e-17\nEpoch 3/24\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9756 - loss: 0.0753\nEpoch 3: val_loss improved from 0.15499 to 0.15153, saving model to ./output/lastbest-43.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 544ms/step - categorical_accuracy: 0.9757 - loss: 0.0752 - val_categorical_accuracy: 0.9509 - val_loss: 0.1515 - learning_rate: 1.1369e-17\nEpoch 4/24\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - categorical_accuracy: 0.9806 - loss: 0.0635\nEpoch 4: val_loss did not improve from 0.15153\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 520ms/step - categorical_accuracy: 0.9806 - loss: 0.0636 - val_categorical_accuracy: 0.9335 - val_loss: 0.1986 - learning_rate: 1.1369e-17\nEpoch 5/24\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9763 - loss: 0.0803\nEpoch 5: val_loss did not improve from 0.15153\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 523ms/step - categorical_accuracy: 0.9763 - loss: 0.0801 - val_categorical_accuracy: 0.9480 - val_loss: 0.1581 - learning_rate: 1.1369e-17\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 77).\nRestarting from last best val_loss at local epoch 0 (global epoch 73).\nEpoch 1/23\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - categorical_accuracy: 0.9833 - loss: 0.0736\nEpoch 1: val_loss improved from inf to 0.17590, saving model to ./output/lastbest-44.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 596ms/step - categorical_accuracy: 0.9832 - loss: 0.0737 - val_categorical_accuracy: 0.9393 - val_loss: 0.1759 - learning_rate: 5.6843e-18\nEpoch 2/23\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9728 - loss: 0.0677\nEpoch 2: val_loss improved from 0.17590 to 0.16551, saving model to ./output/lastbest-44.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 542ms/step - categorical_accuracy: 0.9729 - loss: 0.0677 - val_categorical_accuracy: 0.9451 - val_loss: 0.1655 - learning_rate: 5.6843e-18\nEpoch 3/23\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9766 - loss: 0.0851\nEpoch 3: val_loss improved from 0.16551 to 0.13687, saving model to ./output/lastbest-44.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 544ms/step - categorical_accuracy: 0.9767 - loss: 0.0848 - val_categorical_accuracy: 0.9566 - val_loss: 0.1369 - learning_rate: 5.6843e-18\nEpoch 4/23\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9778 - loss: 0.0707\nEpoch 4: val_loss improved from 0.13687 to 0.13307, saving model to ./output/lastbest-44.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 550ms/step - categorical_accuracy: 0.9778 - loss: 0.0707 - val_categorical_accuracy: 0.9480 - val_loss: 0.1331 - learning_rate: 5.6843e-18\nEpoch 5/23\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9744 - loss: 0.0735\nEpoch 5: val_loss did not improve from 0.13307\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - categorical_accuracy: 0.9744 - loss: 0.0735 - val_categorical_accuracy: 0.9422 - val_loss: 0.1678 - learning_rate: 5.6843e-18\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 78).\nRestarting from last best val_loss at local epoch 0 (global epoch 74).\nEpoch 1/22\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - categorical_accuracy: 0.9794 - loss: 0.0673\nEpoch 1: val_loss improved from inf to 0.17141, saving model to ./output/lastbest-45.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 595ms/step - categorical_accuracy: 0.9793 - loss: 0.0674 - val_categorical_accuracy: 0.9451 - val_loss: 0.1714 - learning_rate: 2.8422e-18\nEpoch 2/22\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9789 - loss: 0.0686\nEpoch 2: val_loss improved from 0.17141 to 0.16865, saving model to ./output/lastbest-45.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9789 - loss: 0.0687 - val_categorical_accuracy: 0.9393 - val_loss: 0.1687 - learning_rate: 2.8422e-18\nEpoch 3/22\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9785 - loss: 0.0757\nEpoch 3: val_loss did not improve from 0.16865\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9785 - loss: 0.0756 - val_categorical_accuracy: 0.9509 - val_loss: 0.1905 - learning_rate: 2.8422e-18\nEpoch 4/22\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9842 - loss: 0.0613\nEpoch 4: val_loss did not improve from 0.16865\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9841 - loss: 0.0615 - val_categorical_accuracy: 0.9509 - val_loss: 0.1773 - learning_rate: 2.8422e-18\nEpoch 5/22\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9757 - loss: 0.0805\nEpoch 5: val_loss did not improve from 0.16865\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9757 - loss: 0.0804 - val_categorical_accuracy: 0.9538 - val_loss: 0.1823 - learning_rate: 2.8422e-18\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 79).\nRestarting from last best val_loss at local epoch 0 (global epoch 75).\nEpoch 1/21\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - categorical_accuracy: 0.9830 - loss: 0.0589\nEpoch 1: val_loss improved from inf to 0.15425, saving model to ./output/lastbest-46.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 593ms/step - categorical_accuracy: 0.9830 - loss: 0.0589 - val_categorical_accuracy: 0.9335 - val_loss: 0.1542 - learning_rate: 1.4211e-18\nEpoch 2/21\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - categorical_accuracy: 0.9824 - loss: 0.0556\nEpoch 2: val_loss improved from 0.15425 to 0.14497, saving model to ./output/lastbest-46.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - categorical_accuracy: 0.9824 - loss: 0.0557 - val_categorical_accuracy: 0.9480 - val_loss: 0.1450 - learning_rate: 1.4211e-18\nEpoch 3/21\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9809 - loss: 0.0708\nEpoch 3: val_loss did not improve from 0.14497\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9808 - loss: 0.0709 - val_categorical_accuracy: 0.9480 - val_loss: 0.1859 - learning_rate: 1.4211e-18\nEpoch 4/21\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - categorical_accuracy: 0.9785 - loss: 0.0788\nEpoch 4: val_loss did not improve from 0.14497\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - categorical_accuracy: 0.9785 - loss: 0.0787 - val_categorical_accuracy: 0.9393 - val_loss: 0.1777 - learning_rate: 1.4211e-18\nEpoch 5/21\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9828 - loss: 0.0606\nEpoch 5: val_loss did not improve from 0.14497\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9828 - loss: 0.0606 - val_categorical_accuracy: 0.9393 - val_loss: 0.1898 - learning_rate: 1.4211e-18\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 80).\nRestarting from last best val_loss at local epoch 0 (global epoch 76).\nEpoch 1/20\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - categorical_accuracy: 0.9774 - loss: 0.0697\nEpoch 1: val_loss improved from inf to 0.15545, saving model to ./output/lastbest-47.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 595ms/step - categorical_accuracy: 0.9774 - loss: 0.0696 - val_categorical_accuracy: 0.9422 - val_loss: 0.1555 - learning_rate: 7.1054e-19\nEpoch 2/20\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9806 - loss: 0.0734\nEpoch 2: val_loss improved from 0.15545 to 0.14934, saving model to ./output/lastbest-47.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 550ms/step - categorical_accuracy: 0.9806 - loss: 0.0734 - val_categorical_accuracy: 0.9538 - val_loss: 0.1493 - learning_rate: 7.1054e-19\nEpoch 3/20\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9815 - loss: 0.0648\nEpoch 3: val_loss did not improve from 0.14934\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9815 - loss: 0.0649 - val_categorical_accuracy: 0.9451 - val_loss: 0.1617 - learning_rate: 7.1054e-19\nEpoch 4/20\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9809 - loss: 0.0644\nEpoch 4: val_loss did not improve from 0.14934\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9808 - loss: 0.0644 - val_categorical_accuracy: 0.9480 - val_loss: 0.1600 - learning_rate: 7.1054e-19\nEpoch 5/20\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9777 - loss: 0.0631\nEpoch 5: val_loss improved from 0.14934 to 0.13786, saving model to ./output/lastbest-47.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 547ms/step - categorical_accuracy: 0.9777 - loss: 0.0631 - val_categorical_accuracy: 0.9393 - val_loss: 0.1379 - learning_rate: 7.1054e-19\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 81).\nRestarting from last best val_loss at local epoch 0 (global epoch 77).\nEpoch 1/19\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - categorical_accuracy: 0.9753 - loss: 0.0724\nEpoch 1: val_loss improved from inf to 0.17320, saving model to ./output/lastbest-48.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 584ms/step - categorical_accuracy: 0.9753 - loss: 0.0723 - val_categorical_accuracy: 0.9566 - val_loss: 0.1732 - learning_rate: 3.5527e-19\nEpoch 2/19\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9712 - loss: 0.0868\nEpoch 2: val_loss improved from 0.17320 to 0.17008, saving model to ./output/lastbest-48.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 550ms/step - categorical_accuracy: 0.9712 - loss: 0.0866 - val_categorical_accuracy: 0.9566 - val_loss: 0.1701 - learning_rate: 3.5527e-19\nEpoch 3/19\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9766 - loss: 0.0752\nEpoch 3: val_loss did not improve from 0.17008\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 537ms/step - categorical_accuracy: 0.9766 - loss: 0.0752 - val_categorical_accuracy: 0.9538 - val_loss: 0.1754 - learning_rate: 3.5527e-19\nEpoch 4/19\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9864 - loss: 0.0590\nEpoch 4: val_loss improved from 0.17008 to 0.13847, saving model to ./output/lastbest-48.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9863 - loss: 0.0591 - val_categorical_accuracy: 0.9509 - val_loss: 0.1385 - learning_rate: 3.5527e-19\nEpoch 5/19\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - categorical_accuracy: 0.9819 - loss: 0.0598\nEpoch 5: val_loss did not improve from 0.13847\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9818 - loss: 0.0599 - val_categorical_accuracy: 0.9451 - val_loss: 0.1823 - learning_rate: 3.5527e-19\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 82).\nRestarting from last best val_loss at local epoch 0 (global epoch 78).\nEpoch 1/18\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - categorical_accuracy: 0.9756 - loss: 0.0701\nEpoch 1: val_loss improved from inf to 0.20016, saving model to ./output/lastbest-49.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 594ms/step - categorical_accuracy: 0.9755 - loss: 0.0702 - val_categorical_accuracy: 0.9335 - val_loss: 0.2002 - learning_rate: 1.7764e-19\nEpoch 2/18\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9703 - loss: 0.0826\nEpoch 2: val_loss improved from 0.20016 to 0.15458, saving model to ./output/lastbest-49.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - categorical_accuracy: 0.9704 - loss: 0.0825 - val_categorical_accuracy: 0.9509 - val_loss: 0.1546 - learning_rate: 1.7764e-19\nEpoch 3/18\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9767 - loss: 0.0642\nEpoch 3: val_loss did not improve from 0.15458\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - categorical_accuracy: 0.9768 - loss: 0.0641 - val_categorical_accuracy: 0.9335 - val_loss: 0.1548 - learning_rate: 1.7764e-19\nEpoch 4/18\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9820 - loss: 0.0602\nEpoch 4: val_loss did not improve from 0.15458\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - categorical_accuracy: 0.9819 - loss: 0.0604 - val_categorical_accuracy: 0.9509 - val_loss: 0.1791 - learning_rate: 1.7764e-19\nEpoch 5/18\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9780 - loss: 0.0671\nEpoch 5: val_loss improved from 0.15458 to 0.13126, saving model to ./output/lastbest-49.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 544ms/step - categorical_accuracy: 0.9780 - loss: 0.0671 - val_categorical_accuracy: 0.9538 - val_loss: 0.1313 - learning_rate: 1.7764e-19\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 83).\nRestarting from last best val_loss at local epoch 0 (global epoch 79).\nEpoch 1/17\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - categorical_accuracy: 0.9788 - loss: 0.0648\nEpoch 1: val_loss improved from inf to 0.15525, saving model to ./output/lastbest-50.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 592ms/step - categorical_accuracy: 0.9788 - loss: 0.0648 - val_categorical_accuracy: 0.9480 - val_loss: 0.1552 - learning_rate: 8.8818e-20\nEpoch 2/17\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - categorical_accuracy: 0.9809 - loss: 0.0575\nEpoch 2: val_loss did not improve from 0.15525\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 560ms/step - categorical_accuracy: 0.9809 - loss: 0.0576 - val_categorical_accuracy: 0.9480 - val_loss: 0.1723 - learning_rate: 8.8818e-20\nEpoch 3/17\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9760 - loss: 0.0697\nEpoch 3: val_loss did not improve from 0.15525\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9761 - loss: 0.0697 - val_categorical_accuracy: 0.9451 - val_loss: 0.1795 - learning_rate: 8.8818e-20\nEpoch 4/17\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9723 - loss: 0.0888\nEpoch 4: val_loss did not improve from 0.15525\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9724 - loss: 0.0885 - val_categorical_accuracy: 0.9538 - val_loss: 0.1555 - learning_rate: 8.8818e-20\nEpoch 5/17\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9787 - loss: 0.0741\nEpoch 5: val_loss did not improve from 0.15525\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - categorical_accuracy: 0.9787 - loss: 0.0741 - val_categorical_accuracy: 0.9422 - val_loss: 0.1882 - learning_rate: 8.8818e-20\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 84).\nRestarting from last best val_loss at local epoch 0 (global epoch 80).\nEpoch 1/16\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - categorical_accuracy: 0.9827 - loss: 0.0672\nEpoch 1: val_loss improved from inf to 0.18308, saving model to ./output/lastbest-51.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 590ms/step - categorical_accuracy: 0.9826 - loss: 0.0672 - val_categorical_accuracy: 0.9422 - val_loss: 0.1831 - learning_rate: 4.4409e-20\nEpoch 2/16\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9858 - loss: 0.0579\nEpoch 2: val_loss improved from 0.18308 to 0.15145, saving model to ./output/lastbest-51.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9856 - loss: 0.0581 - val_categorical_accuracy: 0.9451 - val_loss: 0.1515 - learning_rate: 4.4409e-20\nEpoch 3/16\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9759 - loss: 0.0685\nEpoch 3: val_loss did not improve from 0.15145\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - categorical_accuracy: 0.9759 - loss: 0.0685 - val_categorical_accuracy: 0.9509 - val_loss: 0.1612 - learning_rate: 4.4409e-20\nEpoch 4/16\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - categorical_accuracy: 0.9759 - loss: 0.0780\nEpoch 4: val_loss improved from 0.15145 to 0.13696, saving model to ./output/lastbest-51.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 541ms/step - categorical_accuracy: 0.9759 - loss: 0.0779 - val_categorical_accuracy: 0.9538 - val_loss: 0.1370 - learning_rate: 4.4409e-20\nEpoch 5/16\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - categorical_accuracy: 0.9760 - loss: 0.0790\nEpoch 5: val_loss did not improve from 0.13696\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - categorical_accuracy: 0.9761 - loss: 0.0788 - val_categorical_accuracy: 0.9480 - val_loss: 0.1656 - learning_rate: 4.4409e-20\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 85).\nRestarting from last best val_loss at local epoch 0 (global epoch 81).\nEpoch 1/15\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - categorical_accuracy: 0.9798 - loss: 0.0680\nEpoch 1: val_loss improved from inf to 0.14171, saving model to ./output/lastbest-52.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 650ms/step - categorical_accuracy: 0.9798 - loss: 0.0680 - val_categorical_accuracy: 0.9624 - val_loss: 0.1417 - learning_rate: 2.2204e-20\nEpoch 2/15\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - categorical_accuracy: 0.9826 - loss: 0.0533\nEpoch 2: val_loss did not improve from 0.14171\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 574ms/step - categorical_accuracy: 0.9826 - loss: 0.0535 - val_categorical_accuracy: 0.9538 - val_loss: 0.1483 - learning_rate: 2.2204e-20\nEpoch 3/15\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - categorical_accuracy: 0.9760 - loss: 0.0718\nEpoch 3: val_loss did not improve from 0.14171\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 579ms/step - categorical_accuracy: 0.9761 - loss: 0.0717 - val_categorical_accuracy: 0.9480 - val_loss: 0.1570 - learning_rate: 2.2204e-20\nEpoch 4/15\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - categorical_accuracy: 0.9790 - loss: 0.0677\nEpoch 4: val_loss did not improve from 0.14171\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 581ms/step - categorical_accuracy: 0.9790 - loss: 0.0677 - val_categorical_accuracy: 0.9451 - val_loss: 0.1719 - learning_rate: 2.2204e-20\nEpoch 5/15\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - categorical_accuracy: 0.9801 - loss: 0.0579\nEpoch 5: val_loss did not improve from 0.14171\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 571ms/step - categorical_accuracy: 0.9800 - loss: 0.0581 - val_categorical_accuracy: 0.9509 - val_loss: 0.1472 - learning_rate: 2.2204e-20\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 86).\nRestarting from last best val_loss at local epoch 0 (global epoch 82).\nEpoch 1/14\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - categorical_accuracy: 0.9774 - loss: 0.0603\nEpoch 1: val_loss improved from inf to 0.17152, saving model to ./output/lastbest-53.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 630ms/step - categorical_accuracy: 0.9774 - loss: 0.0604 - val_categorical_accuracy: 0.9595 - val_loss: 0.1715 - learning_rate: 1.1102e-20\nEpoch 2/14\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - categorical_accuracy: 0.9770 - loss: 0.0776\nEpoch 2: val_loss improved from 0.17152 to 0.14925, saving model to ./output/lastbest-53.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 577ms/step - categorical_accuracy: 0.9770 - loss: 0.0774 - val_categorical_accuracy: 0.9509 - val_loss: 0.1493 - learning_rate: 1.1102e-20\nEpoch 3/14\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - categorical_accuracy: 0.9770 - loss: 0.0645\nEpoch 3: val_loss did not improve from 0.14925\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 565ms/step - categorical_accuracy: 0.9771 - loss: 0.0646 - val_categorical_accuracy: 0.9509 - val_loss: 0.1584 - learning_rate: 1.1102e-20\nEpoch 4/14\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - categorical_accuracy: 0.9758 - loss: 0.0761\nEpoch 4: val_loss did not improve from 0.14925\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 571ms/step - categorical_accuracy: 0.9759 - loss: 0.0760 - val_categorical_accuracy: 0.9480 - val_loss: 0.1681 - learning_rate: 1.1102e-20\nEpoch 5/14\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - categorical_accuracy: 0.9840 - loss: 0.0652\nEpoch 5: val_loss did not improve from 0.14925\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - categorical_accuracy: 0.9839 - loss: 0.0652 - val_categorical_accuracy: 0.9538 - val_loss: 0.1649 - learning_rate: 1.1102e-20\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 87).\nRestarting from last best val_loss at local epoch 0 (global epoch 83).\nEpoch 1/13\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - categorical_accuracy: 0.9787 - loss: 0.0691\nEpoch 1: val_loss improved from inf to 0.16319, saving model to ./output/lastbest-54.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 616ms/step - categorical_accuracy: 0.9786 - loss: 0.0692 - val_categorical_accuracy: 0.9451 - val_loss: 0.1632 - learning_rate: 5.5511e-21\nEpoch 2/13\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - categorical_accuracy: 0.9715 - loss: 0.0848\nEpoch 2: val_loss improved from 0.16319 to 0.15949, saving model to ./output/lastbest-54.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 570ms/step - categorical_accuracy: 0.9716 - loss: 0.0845 - val_categorical_accuracy: 0.9509 - val_loss: 0.1595 - learning_rate: 5.5511e-21\nEpoch 3/13\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - categorical_accuracy: 0.9723 - loss: 0.0837\nEpoch 3: val_loss improved from 0.15949 to 0.14811, saving model to ./output/lastbest-54.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 570ms/step - categorical_accuracy: 0.9724 - loss: 0.0835 - val_categorical_accuracy: 0.9509 - val_loss: 0.1481 - learning_rate: 5.5511e-21\nEpoch 4/13\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - categorical_accuracy: 0.9823 - loss: 0.0576\nEpoch 4: val_loss did not improve from 0.14811\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 556ms/step - categorical_accuracy: 0.9822 - loss: 0.0578 - val_categorical_accuracy: 0.9451 - val_loss: 0.1663 - learning_rate: 5.5511e-21\nEpoch 5/13\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - categorical_accuracy: 0.9825 - loss: 0.0662\nEpoch 5: val_loss did not improve from 0.14811\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 543ms/step - categorical_accuracy: 0.9825 - loss: 0.0663 - val_categorical_accuracy: 0.9422 - val_loss: 0.1815 - learning_rate: 5.5511e-21\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 88).\nRestarting from last best val_loss at local epoch 0 (global epoch 84).\nEpoch 1/12\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - categorical_accuracy: 0.9823 - loss: 0.0581\nEpoch 1: val_loss improved from inf to 0.16548, saving model to ./output/lastbest-55.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 616ms/step - categorical_accuracy: 0.9822 - loss: 0.0583 - val_categorical_accuracy: 0.9538 - val_loss: 0.1655 - learning_rate: 2.7756e-21\nEpoch 2/12\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - categorical_accuracy: 0.9731 - loss: 0.0820\nEpoch 2: val_loss improved from 0.16548 to 0.15847, saving model to ./output/lastbest-55.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 564ms/step - categorical_accuracy: 0.9732 - loss: 0.0818 - val_categorical_accuracy: 0.9422 - val_loss: 0.1585 - learning_rate: 2.7756e-21\nEpoch 3/12\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - categorical_accuracy: 0.9780 - loss: 0.0791\nEpoch 3: val_loss did not improve from 0.15847\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9780 - loss: 0.0790 - val_categorical_accuracy: 0.9538 - val_loss: 0.1678 - learning_rate: 2.7756e-21\nEpoch 4/12\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - categorical_accuracy: 0.9783 - loss: 0.0692\nEpoch 4: val_loss did not improve from 0.15847\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9784 - loss: 0.0691 - val_categorical_accuracy: 0.9451 - val_loss: 0.1689 - learning_rate: 2.7756e-21\nEpoch 5/12\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - categorical_accuracy: 0.9763 - loss: 0.0801\nEpoch 5: val_loss did not improve from 0.15847\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - categorical_accuracy: 0.9763 - loss: 0.0800 - val_categorical_accuracy: 0.9422 - val_loss: 0.1639 - learning_rate: 2.7756e-21\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 89).\nRestarting from last best val_loss at local epoch 0 (global epoch 85).\nEpoch 1/11\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - categorical_accuracy: 0.9761 - loss: 0.0705\nEpoch 1: val_loss improved from inf to 0.17595, saving model to ./output/lastbest-56.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 612ms/step - categorical_accuracy: 0.9761 - loss: 0.0705 - val_categorical_accuracy: 0.9451 - val_loss: 0.1760 - learning_rate: 1.3878e-21\nEpoch 2/11\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - categorical_accuracy: 0.9771 - loss: 0.0752\nEpoch 2: val_loss improved from 0.17595 to 0.16264, saving model to ./output/lastbest-56.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 560ms/step - categorical_accuracy: 0.9771 - loss: 0.0752 - val_categorical_accuracy: 0.9538 - val_loss: 0.1626 - learning_rate: 1.3878e-21\nEpoch 3/11\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - categorical_accuracy: 0.9780 - loss: 0.0794\nEpoch 3: val_loss improved from 0.16264 to 0.15572, saving model to ./output/lastbest-56.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 562ms/step - categorical_accuracy: 0.9781 - loss: 0.0792 - val_categorical_accuracy: 0.9451 - val_loss: 0.1557 - learning_rate: 1.3878e-21\nEpoch 4/11\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9685 - loss: 0.0915\nEpoch 4: val_loss did not improve from 0.15572\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9686 - loss: 0.0912 - val_categorical_accuracy: 0.9480 - val_loss: 0.1742 - learning_rate: 1.3878e-21\nEpoch 5/11\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - categorical_accuracy: 0.9760 - loss: 0.0677\nEpoch 5: val_loss improved from 0.15572 to 0.14810, saving model to ./output/lastbest-56.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 556ms/step - categorical_accuracy: 0.9760 - loss: 0.0678 - val_categorical_accuracy: 0.9451 - val_loss: 0.1481 - learning_rate: 1.3878e-21\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 90).\nRestarting from last best val_loss at local epoch 0 (global epoch 86).\nEpoch 1/10\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - categorical_accuracy: 0.9807 - loss: 0.0619\nEpoch 1: val_loss improved from inf to 0.17183, saving model to ./output/lastbest-57.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 596ms/step - categorical_accuracy: 0.9807 - loss: 0.0620 - val_categorical_accuracy: 0.9364 - val_loss: 0.1718 - learning_rate: 6.9389e-22\nEpoch 2/10\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9822 - loss: 0.0625\nEpoch 2: val_loss improved from 0.17183 to 0.15955, saving model to ./output/lastbest-57.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 547ms/step - categorical_accuracy: 0.9822 - loss: 0.0627 - val_categorical_accuracy: 0.9451 - val_loss: 0.1596 - learning_rate: 6.9389e-22\nEpoch 3/10\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9789 - loss: 0.0640\nEpoch 3: val_loss improved from 0.15955 to 0.15324, saving model to ./output/lastbest-57.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 548ms/step - categorical_accuracy: 0.9789 - loss: 0.0640 - val_categorical_accuracy: 0.9480 - val_loss: 0.1532 - learning_rate: 6.9389e-22\nEpoch 4/10\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - categorical_accuracy: 0.9849 - loss: 0.0543\nEpoch 4: val_loss did not improve from 0.15324\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 541ms/step - categorical_accuracy: 0.9848 - loss: 0.0545 - val_categorical_accuracy: 0.9480 - val_loss: 0.1874 - learning_rate: 6.9389e-22\nEpoch 5/10\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - categorical_accuracy: 0.9796 - loss: 0.0714\nEpoch 5: val_loss improved from 0.15324 to 0.15067, saving model to ./output/lastbest-57.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 547ms/step - categorical_accuracy: 0.9796 - loss: 0.0714 - val_categorical_accuracy: 0.9566 - val_loss: 0.1507 - learning_rate: 6.9389e-22\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 91).\nRestarting from last best val_loss at local epoch 0 (global epoch 87).\nEpoch 1/9\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - categorical_accuracy: 0.9786 - loss: 0.0623\nEpoch 1: val_loss improved from inf to 0.19017, saving model to ./output/lastbest-58.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 592ms/step - categorical_accuracy: 0.9786 - loss: 0.0624 - val_categorical_accuracy: 0.9451 - val_loss: 0.1902 - learning_rate: 3.4694e-22\nEpoch 2/9\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - categorical_accuracy: 0.9832 - loss: 0.0503\nEpoch 2: val_loss improved from 0.19017 to 0.12886, saving model to ./output/lastbest-58.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 556ms/step - categorical_accuracy: 0.9831 - loss: 0.0505 - val_categorical_accuracy: 0.9451 - val_loss: 0.1289 - learning_rate: 3.4694e-22\nEpoch 3/9\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9856 - loss: 0.0518\nEpoch 3: val_loss did not improve from 0.12886\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9855 - loss: 0.0521 - val_categorical_accuracy: 0.9538 - val_loss: 0.1520 - learning_rate: 3.4694e-22\nEpoch 4/9\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - categorical_accuracy: 0.9796 - loss: 0.0616\nEpoch 4: val_loss did not improve from 0.12886\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 543ms/step - categorical_accuracy: 0.9796 - loss: 0.0617 - val_categorical_accuracy: 0.9595 - val_loss: 0.1464 - learning_rate: 3.4694e-22\nEpoch 5/9\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - categorical_accuracy: 0.9793 - loss: 0.0657\nEpoch 5: val_loss did not improve from 0.12886\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 544ms/step - categorical_accuracy: 0.9793 - loss: 0.0658 - val_categorical_accuracy: 0.9364 - val_loss: 0.1655 - learning_rate: 3.4694e-22\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 92).\nRestarting from last best val_loss at local epoch 0 (global epoch 88).\nEpoch 1/8\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - categorical_accuracy: 0.9737 - loss: 0.0860\nEpoch 1: val_loss improved from inf to 0.15119, saving model to ./output/lastbest-59.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 611ms/step - categorical_accuracy: 0.9738 - loss: 0.0858 - val_categorical_accuracy: 0.9451 - val_loss: 0.1512 - learning_rate: 1.7347e-22\nEpoch 2/8\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - categorical_accuracy: 0.9777 - loss: 0.0726\nEpoch 2: val_loss did not improve from 0.15119\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 538ms/step - categorical_accuracy: 0.9777 - loss: 0.0726 - val_categorical_accuracy: 0.9509 - val_loss: 0.1689 - learning_rate: 1.7347e-22\nEpoch 3/8\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9794 - loss: 0.0555\nEpoch 3: val_loss improved from 0.15119 to 0.14203, saving model to ./output/lastbest-59.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 557ms/step - categorical_accuracy: 0.9793 - loss: 0.0557 - val_categorical_accuracy: 0.9480 - val_loss: 0.1420 - learning_rate: 1.7347e-22\nEpoch 4/8\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.9781 - loss: 0.0725\nEpoch 4: val_loss did not improve from 0.14203\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 538ms/step - categorical_accuracy: 0.9780 - loss: 0.0725 - val_categorical_accuracy: 0.9480 - val_loss: 0.1588 - learning_rate: 1.7347e-22\nEpoch 5/8\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9775 - loss: 0.0633\nEpoch 5: val_loss improved from 0.14203 to 0.14121, saving model to ./output/lastbest-59.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9775 - loss: 0.0634 - val_categorical_accuracy: 0.9422 - val_loss: 0.1412 - learning_rate: 1.7347e-22\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 93).\nRestarting from last best val_loss at local epoch 0 (global epoch 89).\nEpoch 1/7\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - categorical_accuracy: 0.9716 - loss: 0.0795\nEpoch 1: val_loss improved from inf to 0.12271, saving model to ./output/lastbest-60.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 590ms/step - categorical_accuracy: 0.9716 - loss: 0.0794 - val_categorical_accuracy: 0.9653 - val_loss: 0.1227 - learning_rate: 8.6736e-23\nEpoch 2/7\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - categorical_accuracy: 0.9822 - loss: 0.0643\nEpoch 2: val_loss did not improve from 0.12271\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 531ms/step - categorical_accuracy: 0.9822 - loss: 0.0643 - val_categorical_accuracy: 0.9566 - val_loss: 0.1481 - learning_rate: 8.6736e-23\nEpoch 3/7\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9806 - loss: 0.0701\nEpoch 3: val_loss did not improve from 0.12271\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - categorical_accuracy: 0.9806 - loss: 0.0701 - val_categorical_accuracy: 0.9509 - val_loss: 0.1665 - learning_rate: 8.6736e-23\nEpoch 4/7\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - categorical_accuracy: 0.9809 - loss: 0.0605\nEpoch 4: val_loss did not improve from 0.12271\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9808 - loss: 0.0606 - val_categorical_accuracy: 0.9451 - val_loss: 0.1542 - learning_rate: 8.6736e-23\nEpoch 5/7\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - categorical_accuracy: 0.9781 - loss: 0.0706\nEpoch 5: val_loss did not improve from 0.12271\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 521ms/step - categorical_accuracy: 0.9781 - loss: 0.0705 - val_categorical_accuracy: 0.9480 - val_loss: 0.1670 - learning_rate: 8.6736e-23\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 94).\nRestarting from last best val_loss at local epoch 0 (global epoch 90).\nEpoch 1/6\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - categorical_accuracy: 0.9840 - loss: 0.0696\nEpoch 1: val_loss improved from inf to 0.16097, saving model to ./output/lastbest-61.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 590ms/step - categorical_accuracy: 0.9840 - loss: 0.0696 - val_categorical_accuracy: 0.9595 - val_loss: 0.1610 - learning_rate: 4.3368e-23\nEpoch 2/6\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - categorical_accuracy: 0.9762 - loss: 0.0631\nEpoch 2: val_loss improved from 0.16097 to 0.13555, saving model to ./output/lastbest-61.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 553ms/step - categorical_accuracy: 0.9763 - loss: 0.0631 - val_categorical_accuracy: 0.9509 - val_loss: 0.1355 - learning_rate: 4.3368e-23\nEpoch 3/6\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - categorical_accuracy: 0.9848 - loss: 0.0628\nEpoch 3: val_loss did not improve from 0.13555\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - categorical_accuracy: 0.9848 - loss: 0.0629 - val_categorical_accuracy: 0.9538 - val_loss: 0.1482 - learning_rate: 4.3368e-23\nEpoch 4/6\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - categorical_accuracy: 0.9744 - loss: 0.0837\nEpoch 4: val_loss did not improve from 0.13555\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - categorical_accuracy: 0.9744 - loss: 0.0835 - val_categorical_accuracy: 0.9480 - val_loss: 0.1682 - learning_rate: 4.3368e-23\nEpoch 5/6\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - categorical_accuracy: 0.9835 - loss: 0.0550\nEpoch 5: val_loss did not improve from 0.13555\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 522ms/step - categorical_accuracy: 0.9834 - loss: 0.0552 - val_categorical_accuracy: 0.9451 - val_loss: 0.1419 - learning_rate: 4.3368e-23\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nEarly stopping triggered after local epoch 4 (global epoch 95).\nRestarting from last best val_loss at local epoch 0 (global epoch 91).\nEpoch 1/5\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - categorical_accuracy: 0.9720 - loss: 0.0806\nEpoch 1: val_loss improved from inf to 0.17981, saving model to ./output/lastbest-62.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 590ms/step - categorical_accuracy: 0.9721 - loss: 0.0804 - val_categorical_accuracy: 0.9538 - val_loss: 0.1798 - learning_rate: 2.1684e-23\nEpoch 2/5\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 0.9761 - loss: 0.0717\nEpoch 2: val_loss improved from 0.17981 to 0.17020, saving model to ./output/lastbest-62.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9761 - loss: 0.0717 - val_categorical_accuracy: 0.9451 - val_loss: 0.1702 - learning_rate: 2.1684e-23\nEpoch 3/5\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9769 - loss: 0.0828\nEpoch 3: val_loss did not improve from 0.17020\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9770 - loss: 0.0826 - val_categorical_accuracy: 0.9480 - val_loss: 0.1830 - learning_rate: 2.1684e-23\nEpoch 4/5\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - categorical_accuracy: 0.9779 - loss: 0.0636\nEpoch 4: val_loss did not improve from 0.17020\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - categorical_accuracy: 0.9778 - loss: 0.0637 - val_categorical_accuracy: 0.9451 - val_loss: 0.1808 - learning_rate: 2.1684e-23\nEpoch 5/5\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - categorical_accuracy: 0.9867 - loss: 0.0549\nEpoch 5: val_loss improved from 0.17020 to 0.11617, saving model to ./output/lastbest-62.keras\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - categorical_accuracy: 0.9867 - loss: 0.0550 - val_categorical_accuracy: 0.9653 - val_loss: 0.1162 - learning_rate: 2.1684e-23\nRestoring model weights from the end of the best epoch: 5.\nCompleted training after 100 epochs.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Save last best model info\nwith open(output_directory + \"last_best_models.csv\", 'w', newline='') as file:\n     writer = csv.writer(file, delimiter=',')\n     writer.writerow(['Model file', 'Global epoch', 'Validation loss'])\n     for i in range(restarts + 1):\n         writer.writerow([\"lastbest-{}.keras\".format(i), last_best_epochs[i], last_best_losses[i]])\n    # Load the last best model\nmodel = load_model(output_directory + \"lastbest-{}.keras\".format(last_best_losses.index(min(last_best_losses))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T08:47:30.889565Z","iopub.execute_input":"2025-03-09T08:47:30.889943Z","iopub.status.idle":"2025-03-09T08:47:31.681689Z","shell.execute_reply.started":"2025-03-09T08:47:30.889916Z","shell.execute_reply":"2025-03-09T08:47:31.680990Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Evaluate model on test subset for kth fold\npredictions = model.predict(test_data_generator)\ny_true=np.argmax(test_data_generator.labels,axis=1)\ny_pred=np.argmax(predictions, axis=1)\n# y_pred[np.max(predictions, axis=1) < 1 / 9]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T08:47:31.683310Z","iopub.execute_input":"2025-03-09T08:47:31.683583Z","iopub.status.idle":"2025-03-09T08:47:35.381284Z","shell.execute_reply.started":"2025-03-09T08:47:31.683561Z","shell.execute_reply":"2025-03-09T08:47:35.380619Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Generate and print classification metrics and confusion matrix\n\nprint(classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES))\nreport = classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES, output_dict=True)\nwith open(output_directory + 'classification_report.csv', 'w') as f:\n    for key in report.keys():\n        f.write(\"%s,%s\\n\" % (key, report[key]))\nconf_arr = confusion_matrix(y_true, y_pred, labels=CLASSES)\nprint(conf_arr)\nnp.savetxt(output_directory + \"confusion_matrix.csv\", conf_arr, delimiter=\",\")\n\n# Clear model from GPU after each iteration\nprint(\"Finished testing\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T08:47:35.382257Z","iopub.execute_input":"2025-03-09T08:47:35.382494Z","iopub.status.idle":"2025-03-09T08:47:35.412121Z","shell.execute_reply.started":"2025-03-09T08:47:35.382474Z","shell.execute_reply":"2025-03-09T08:47:35.411293Z"}},"outputs":[{"name":"stdout","text":"                precision    recall  f1-score   support\n\n  Chinee Apple       0.94      0.94      0.94        32\n       Lantana       1.00      1.00      1.00         1\n   Parkinsonia       0.00      0.00      0.00         1\n    Parthenium       0.95      0.98      0.96        94\nPrickly Acacia       0.95      0.95      0.95       120\n   Rubber Vine       0.94      0.92      0.93        78\n     Siam Weed       0.96      0.96      0.96        24\n    Snake Weed       0.00      0.00      0.00         0\n     Negatives       0.00      0.00      0.00         2\n\n     micro avg       0.94      0.94      0.94       352\n     macro avg       0.64      0.64      0.64       352\n  weighted avg       0.94      0.94      0.94       352\n\n[[ 30   0   0   0   2   0   0   0   0]\n [  0   1   0   0   0   0   0   0   0]\n [  0   0   0   0   0   1   0   0   0]\n [  0   0   0  92   0   2   0   0   0]\n [  1   0   0   1 114   2   1   0   1]\n [  0   0   0   4   2  72   0   0   0]\n [  1   0   0   0   0   0  23   0   0]\n [  0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   2   0   0   0   0]]\nFinished testing\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!zip -r ./output.zip ./output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T08:47:35.412891Z","iopub.execute_input":"2025-03-09T08:47:35.413124Z","iopub.status.idle":"2025-03-09T08:52:47.921768Z","shell.execute_reply.started":"2025-03-09T08:47:35.413104Z","shell.execute_reply":"2025-03-09T08:52:47.920477Z"}},"outputs":[{"name":"stdout","text":"  adding: output/ (stored 0%)\n  adding: output/lastbest-60.keras (deflated 9%)\n  adding: output/lastbest-20.keras (deflated 9%)\n  adding: output/lastbest-15.keras (deflated 9%)\n  adding: output/lastbest-11.keras (deflated 9%)\n  adding: output/train/ (stored 0%)\n  adding: output/train/events.out.tfevents.1741503230.e9bded963883.31.50.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741501642.e9bded963883.31.34.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741509520.e9bded963883.31.120.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741499545.e9bded963883.31.12.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741509338.e9bded963883.31.118.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741498326.e9bded963883.31.2.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741499924.e9bded963883.31.16.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741501463.e9bded963883.31.32.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741508976.e9bded963883.31.114.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741505007.e9bded963883.31.70.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741500647.e9bded963883.31.24.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741506968.e9bded963883.31.92.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741506074.e9bded963883.31.82.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741507504.e9bded963883.31.98.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741502004.e9bded963883.31.38.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741500104.e9bded963883.31.18.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741506433.e9bded963883.31.86.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741502358.e9bded963883.31.42.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741500826.e9bded963883.31.26.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741501824.e9bded963883.31.36.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741505362.e9bded963883.31.74.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741507861.e9bded963883.31.102.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741504649.e9bded963883.31.66.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741505895.e9bded963883.31.80.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741501102.e9bded963883.31.28.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741498796.e9bded963883.31.6.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741506252.e9bded963883.31.84.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741499346.e9bded963883.31.10.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741508608.e9bded963883.31.110.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741503055.e9bded963883.31.48.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741502535.e9bded963883.31.44.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741508041.e9bded963883.31.104.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741507683.e9bded963883.31.100.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741499144.e9bded963883.31.8.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741503764.e9bded963883.31.56.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741500285.e9bded963883.31.20.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741508792.e9bded963883.31.112.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741503587.e9bded963883.31.54.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741502878.e9bded963883.31.46.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741509874.e9bded963883.31.124.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741503940.e9bded963883.31.58.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741509157.e9bded963883.31.116.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741504296.e9bded963883.31.62.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741498597.e9bded963883.31.4.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741505185.e9bded963883.31.72.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741508233.e9bded963883.31.106.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741502181.e9bded963883.31.40.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741509696.e9bded963883.31.122.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741505718.e9bded963883.31.78.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741505542.e9bded963883.31.76.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741506789.e9bded963883.31.90.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741504471.e9bded963883.31.64.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741504828.e9bded963883.31.68.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741501281.e9bded963883.31.30.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741500466.e9bded963883.31.22.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741497386.e9bded963883.31.0.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741506609.e9bded963883.31.88.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741508422.e9bded963883.31.108.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741504118.e9bded963883.31.60.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741507324.e9bded963883.31.96.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741499743.e9bded963883.31.14.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741507145.e9bded963883.31.94.v2 (deflated 90%)\n  adding: output/train/events.out.tfevents.1741503408.e9bded963883.31.52.v2 (deflated 90%)\n  adding: output/lastbest-28.keras (deflated 9%)\n  adding: output/lastbest-2.keras (deflated 9%)\n  adding: output/lastbest-50.keras (deflated 9%)\n  adding: output/lastbest-42.keras (deflated 9%)\n  adding: output/lastbest-14.keras (deflated 9%)\n  adding: output/lastbest-12.keras (deflated 9%)\n  adding: output/lastbest-35.keras (deflated 9%)\n  adding: output/validation/ (stored 0%)\n  adding: output/validation/events.out.tfevents.1741504864.e9bded963883.31.69.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741507004.e9bded963883.31.93.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741504154.e9bded963883.31.61.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741507540.e9bded963883.31.99.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741502040.e9bded963883.31.39.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741503623.e9bded963883.31.55.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741509732.e9bded963883.31.123.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741501499.e9bded963883.31.33.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741502217.e9bded963883.31.41.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741502913.e9bded963883.31.47.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741505221.e9bded963883.31.73.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741504685.e9bded963883.31.67.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741499961.e9bded963883.31.17.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741498836.e9bded963883.31.7.v2 (deflated 73%)\n  adding: output/validation/events.out.tfevents.1741506288.e9bded963883.31.85.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741507181.e9bded963883.31.95.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741504508.e9bded963883.31.65.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741508271.e9bded963883.31.107.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741508645.e9bded963883.31.111.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741499586.e9bded963883.31.13.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741505931.e9bded963883.31.81.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741507360.e9bded963883.31.97.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741508080.e9bded963883.31.105.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741508829.e9bded963883.31.113.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741506645.e9bded963883.31.89.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741509193.e9bded963883.31.117.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741498366.e9bded963883.31.3.v2 (deflated 70%)\n  adding: output/validation/events.out.tfevents.1741505399.e9bded963883.31.75.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741501318.e9bded963883.31.31.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741501679.e9bded963883.31.35.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741497454.e9bded963883.31.1.v2 (deflated 78%)\n  adding: output/validation/events.out.tfevents.1741508459.e9bded963883.31.109.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741503090.e9bded963883.31.49.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741498637.e9bded963883.31.5.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741506110.e9bded963883.31.83.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741509012.e9bded963883.31.115.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741507719.e9bded963883.31.101.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741509375.e9bded963883.31.119.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741501861.e9bded963883.31.37.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741507897.e9bded963883.31.103.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741504331.e9bded963883.31.63.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741503800.e9bded963883.31.57.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741505754.e9bded963883.31.79.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741509910.e9bded963883.31.125.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741500683.e9bded963883.31.25.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741505577.e9bded963883.31.77.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741502393.e9bded963883.31.43.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741499184.e9bded963883.31.9.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741503266.e9bded963883.31.51.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741506825.e9bded963883.31.91.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741500141.e9bded963883.31.19.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741502571.e9bded963883.31.45.v2 (deflated 74%)\n  adding: output/validation/events.out.tfevents.1741509556.e9bded963883.31.121.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741499781.e9bded963883.31.15.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741503976.e9bded963883.31.59.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741505043.e9bded963883.31.71.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741499387.e9bded963883.31.11.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741500503.e9bded963883.31.23.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741500321.e9bded963883.31.21.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741506469.e9bded963883.31.87.v2 (deflated 67%)\n  adding: output/validation/events.out.tfevents.1741500862.e9bded963883.31.27.v2 (deflated 73%)\n  adding: output/validation/events.out.tfevents.1741501139.e9bded963883.31.29.v2 (deflated 68%)\n  adding: output/validation/events.out.tfevents.1741503444.e9bded963883.31.53.v2 (deflated 67%)\n  adding: output/lastbest-5.keras (deflated 9%)\n  adding: output/lastbest-6.keras (deflated 9%)\n  adding: output/lastbest-33.keras (deflated 9%)\n  adding: output/lastbest-40.keras (deflated 9%)\n  adding: output/lastbest-26.keras (deflated 9%)\n  adding: output/lastbest-30.keras (deflated 9%)\n  adding: output/lastbest-54.keras (deflated 9%)\n  adding: output/lastbest-52.keras (deflated 9%)\n  adding: output/lastbest-9.keras (deflated 9%)\n  adding: output/lastbest-10.keras (deflated 9%)\n  adding: output/lastbest-36.keras (deflated 9%)\n  adding: output/lastbest-17.keras (deflated 9%)\n  adding: output/last_best_models.csv (deflated 64%)\n  adding: output/classification_report.csv (deflated 69%)\n  adding: output/lastbest-49.keras (deflated 9%)\n  adding: output/lastbest-61.keras (deflated 9%)\n  adding: output/lastbest-48.keras (deflated 9%)\n  adding: output/lastbest-3.keras\nzip I/O error: No space left on device\nzip error: Output file write failure (write error on zip file)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom keras.models import load_model\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\n\n# Load the trained model\nMODEL_PATH = \"/kaggle/working/output/lastbest-0.keras\"\nmodel = load_model(MODEL_PATH)\n\n# Define class labels\nCLASS_NAMES = ['Chinee Apple', 'Lantana', 'Parkinsonia', 'Parthenium', 'Prickly Acacia', \n               'Rubber Vine', 'Siam Weed', 'Snake Weed', 'Negative']  \n\ndef predict_image(image_path):\n    \"\"\"Loads an image, preprocesses it, and predicts the weed type.\"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # Resize to match model input size\n    IMG_SIZE = (224, 224)  # Ensure this matches the training size\n    image = cv2.resize(image, IMG_SIZE)\n    \n    # Convert to array and preprocess\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    image = preprocess_input(image)  # Normalize pixel values\n    \n    # Make prediction\n    predictions = model.predict(image)\n    \n    # Get the highest probability class\n    predicted_class = CLASS_NAMES[np.argmax(predictions)]\n    confidence = np.max(predictions) * 100\n    \n    print(f\"Predicted Class: {predicted_class} (Confidence: {confidence:.2f}%)\")\n    return predicted_class, confidence\n\n# Example Usage:\nimage_path = \"/kaggle/input/deepweeds/images/20160928-140337-0.jpg\"  # Change this to your test image\npredict_image(image_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T08:52:47.922993Z","iopub.execute_input":"2025-03-09T08:52:47.923254Z","iopub.status.idle":"2025-03-09T08:52:51.674633Z","shell.execute_reply.started":"2025-03-09T08:52:47.923230Z","shell.execute_reply":"2025-03-09T08:52:51.673924Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\nPredicted Class: Lantana (Confidence: 100.00%)\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('Lantana', 100.0)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}